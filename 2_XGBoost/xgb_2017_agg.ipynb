{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Documentation\n",
    "\n",
    "aggregation encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T14:54:01.556584Z",
     "iopub.status.busy": "2025-01-22T14:54:01.556382Z",
     "iopub.status.idle": "2025-01-22T14:54:08.029817Z",
     "shell.execute_reply": "2025-01-22T14:54:08.029282Z"
    }
   },
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import csv\n",
    "import optuna\n",
    "import xgboost as xgb\n",
    "from optuna.integration import XGBoostPruningCallback\n",
    "from train_evaluate import calculate_metrics\n",
    "from ensemble_encode import agg_encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T14:54:08.032681Z",
     "iopub.status.busy": "2025-01-22T14:54:08.032307Z",
     "iopub.status.idle": "2025-01-22T14:54:08.034974Z",
     "shell.execute_reply": "2025-01-22T14:54:08.034627Z"
    }
   },
   "outputs": [],
   "source": [
    "num_act = 29\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T14:54:08.036838Z",
     "iopub.status.busy": "2025-01-22T14:54:08.036630Z",
     "iopub.status.idle": "2025-01-22T14:54:08.038808Z",
     "shell.execute_reply": "2025-01-22T14:54:08.038466Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set printed tensor format\n",
    "torch.set_printoptions(sci_mode=False, precision=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T14:54:08.040692Z",
     "iopub.status.busy": "2025-01-22T14:54:08.040490Z",
     "iopub.status.idle": "2025-01-22T14:54:08.043020Z",
     "shell.execute_reply": "2025-01-22T14:54:08.042686Z"
    }
   },
   "outputs": [],
   "source": [
    "# define file path\n",
    "train_prefix_act_tensor_path = '/scratch/leuven/370/vsc37039/tensor_2017_0616/train_prefix_act_0616_l.pt'\n",
    "train_prefix_time_tensor_path = '/scratch/leuven/370/vsc37039/tensor_2017_0616/train_prefix_time_0616_l.pt'\n",
    "train_suffix_act_tensor_path = '/scratch/leuven/370/vsc37039/tensor_2017_0616/train_suffix_act_0616.pt'\n",
    "\n",
    "val_prefix_act_tensor_path = '/scratch/leuven/370/vsc37039/tensor_2017_0616/val_prefix_act_0616_l.pt'\n",
    "val_prefix_time_tensor_path = '/scratch/leuven/370/vsc37039/tensor_2017_0616/val_prefix_time_0616_l.pt'\n",
    "val_suffix_act_tensor_path = '/scratch/leuven/370/vsc37039/tensor_2017_0616/val_suffix_act_0616.pt'\n",
    "\n",
    "test_prefix_act_tensor_path = '/scratch/leuven/370/vsc37039/tensor_2017_0616/test_prefix_act_0616_l.pt'\n",
    "test_prefix_time_tensor_path = '/scratch/leuven/370/vsc37039/tensor_2017_0616/test_prefix_time_0616_l.pt'\n",
    "test_suffix_act_tensor_path = '/scratch/leuven/370/vsc37039/tensor_2017_0616/test_suffix_act_0616.pt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T14:54:08.044864Z",
     "iopub.status.busy": "2025-01-22T14:54:08.044669Z",
     "iopub.status.idle": "2025-01-22T14:54:10.898353Z",
     "shell.execute_reply": "2025-01-22T14:54:10.897892Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_240567/55898070.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  train_prefix_act_tensor = torch.load(train_prefix_act_tensor_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([630994, 87])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_240567/55898070.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  train_prefix_time_tensor = torch.load(train_prefix_time_tensor_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([630994, 87, 2])\n"
     ]
    }
   ],
   "source": [
    "train_prefix_act_tensor = torch.load(train_prefix_act_tensor_path)\n",
    "print(train_prefix_act_tensor.shape)\n",
    "\n",
    "train_prefix_time_tensor = torch.load(train_prefix_time_tensor_path)\n",
    "print(train_prefix_time_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 5])\n",
      "tensor([[-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [     0.000,      0.000],\n",
      "        [     0.003,      0.003]])\n"
     ]
    }
   ],
   "source": [
    "print(train_prefix_act_tensor[1])\n",
    "print(train_prefix_time_tensor[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(630994, 30)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = agg_encode(train_prefix_act_tensor, train_prefix_time_tensor, num_act)\n",
    "print(X_train.shape)\n",
    "type(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 1.        , 1.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.0015388 , 0.00158357],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## X_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([150877, 87])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_240567/2509626994.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  val_prefix_act_tensor = torch.load(val_prefix_act_tensor_path)\n",
      "/tmp/ipykernel_240567/2509626994.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  val_prefix_time_tensor = torch.load(val_prefix_time_tensor_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([150877, 87, 2])\n"
     ]
    }
   ],
   "source": [
    "val_prefix_act_tensor = torch.load(val_prefix_act_tensor_path)\n",
    "print(val_prefix_act_tensor.shape)\n",
    "\n",
    "val_prefix_time_tensor = torch.load(val_prefix_time_tensor_path)\n",
    "print(val_prefix_time_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 5])\n",
      "tensor([[-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [     0.000,      0.000],\n",
      "        [     0.003,      0.003]])\n"
     ]
    }
   ],
   "source": [
    "print(val_prefix_act_tensor[1])\n",
    "print(val_prefix_time_tensor[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150877, 30)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val = agg_encode(val_prefix_act_tensor, val_prefix_time_tensor, num_act)\n",
    "print(X_val.shape)\n",
    "type(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 1.        , 1.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.00138183, 0.00142204],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_240567/3558777084.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  test_prefix_act_tensor = torch.load(test_prefix_act_tensor_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([241181, 87])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_240567/3558777084.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  test_prefix_time_tensor = torch.load(test_prefix_time_tensor_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([241181, 87, 2])\n"
     ]
    }
   ],
   "source": [
    "test_prefix_act_tensor = torch.load(test_prefix_act_tensor_path)\n",
    "print(test_prefix_act_tensor.shape)\n",
    "\n",
    "test_prefix_time_tensor = torch.load(test_prefix_time_tensor_path)\n",
    "print(test_prefix_time_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 8])\n",
      "tensor([[-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [     0.000,      0.000],\n",
      "        [     0.000,      0.000]])\n"
     ]
    }
   ],
   "source": [
    "print(test_prefix_act_tensor[1])\n",
    "print(test_prefix_time_tensor[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(241181, 30)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = agg_encode(test_prefix_act_tensor, test_prefix_time_tensor, num_act)\n",
    "print(X_test.shape)\n",
    "type(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 1.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 1.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       6.5577959e-05, 6.7485984e-05], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T14:54:11.560130Z",
     "iopub.status.busy": "2025-01-22T14:54:11.559916Z",
     "iopub.status.idle": "2025-01-22T14:54:11.756015Z",
     "shell.execute_reply": "2025-01-22T14:54:11.755620Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_240567/296722895.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  train_suffix_act_tensor = torch.load(train_suffix_act_tensor_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([630994, 87])\n",
      "torch.Size([630994])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_suffix_act_tensor = torch.load(train_suffix_act_tensor_path)\n",
    "print(train_suffix_act_tensor.shape)\n",
    "\n",
    "y_train_tensor = train_suffix_act_tensor[:, 0]\n",
    "print(y_train_tensor.shape)\n",
    "\n",
    "y_train = y_train_tensor.numpy()\n",
    "type(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T14:54:11.820173Z",
     "iopub.status.busy": "2025-01-22T14:54:11.819934Z",
     "iopub.status.idle": "2025-01-22T14:54:11.840901Z",
     "shell.execute_reply": "2025-01-22T14:54:11.840523Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([150877, 87])\n",
      "torch.Size([150877])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_240567/3081499601.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  val_suffix_act_tensor = torch.load(val_suffix_act_tensor_path)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_suffix_act_tensor = torch.load(val_suffix_act_tensor_path)\n",
    "print(val_suffix_act_tensor.shape)\n",
    "\n",
    "y_val_tensor = val_suffix_act_tensor[:, 0]\n",
    "print(y_val_tensor.shape)\n",
    "\n",
    "y_val = y_val_tensor.numpy()\n",
    "type(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_240567/515295135.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  test_suffix_act_tensor = torch.load(test_suffix_act_tensor_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([241181, 87])\n",
      "torch.Size([241181])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_suffix_act_tensor = torch.load(test_suffix_act_tensor_path)\n",
    "print(test_suffix_act_tensor.shape)\n",
    "\n",
    "y_test_tensor = test_suffix_act_tensor[:, 0]\n",
    "print(y_test_tensor.shape)\n",
    "\n",
    "y_test = y_test_tensor.numpy()\n",
    "type(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T15:56:17.437649Z",
     "iopub.status.busy": "2025-01-22T15:56:17.437337Z",
     "iopub.status.idle": "2025-01-22T15:56:17.504947Z",
     "shell.execute_reply": "2025-01-22T15:56:17.504535Z"
    }
   },
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    # Define the search space for hyperparameters\n",
    "    param = {\n",
    "        'objective': 'multi:softprob',\n",
    "        'eval_metric': 'mlogloss',\n",
    "        'num_class': num_act,\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 12),\n",
    "        'min_child_weight': trial.suggest_float('min_child_weight', 1, 10.0),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "        'lambda': trial.suggest_float('lambda', 0.1, 10.0),\n",
    "        'eta': trial.suggest_float('eta', 0.01, 0.3, log=True)\n",
    "    }\n",
    "\n",
    "    # Convert the data into DMatrix format\n",
    "    dtrain = xgb.DMatrix(data=X_train, label=y_train)\n",
    "    dvalid = xgb.DMatrix(data=X_val, label=y_val)\n",
    "\n",
    "    # Define the pruning callback for early stopping\n",
    "    pruning_callback = optuna.integration.XGBoostPruningCallback(trial, 'validation-mlogloss')\n",
    "\n",
    "    # Train the model with early stopping\n",
    "    model = xgb.train(param, \n",
    "                      dtrain, \n",
    "                      evals=[(dvalid, 'validation')], \n",
    "                      num_boost_round = 100000, \n",
    "                      early_stopping_rounds=20, \n",
    "                      callbacks=[pruning_callback],\n",
    "                      verbose_eval=False)\n",
    "\n",
    "    return model.best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T15:56:17.507030Z",
     "iopub.status.busy": "2025-01-22T15:56:17.506702Z",
     "iopub.status.idle": "2025-01-22T18:47:16.334424Z",
     "shell.execute_reply": "2025-01-22T18:47:16.333569Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-09 16:31:08,835] A new study created in memory with name: no-name-7df7258c-5ab9-4f65-b0b5-329a43b6b81d\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95cf19b54009437285cddee8b3d3f176",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-09 16:40:22,776] Trial 0 finished with value: 0.4159197700436676 and parameters: {'max_depth': 3, 'min_child_weight': 8.019269130161032, 'subsample': 0.7192046157204468, 'colsample_bytree': 0.8617325889154706, 'lambda': 9.782096168766367, 'eta': 0.062434364533734486}. Best is trial 0 with value: 0.4159197700436676.\n",
      "[I 2025-07-09 16:41:24,029] Trial 1 finished with value: 0.41115179380153266 and parameters: {'max_depth': 8, 'min_child_weight': 1.648460200237854, 'subsample': 0.6342194900509356, 'colsample_bytree': 0.74994125041278, 'lambda': 6.82437696159731, 'eta': 0.153893406647721}. Best is trial 1 with value: 0.41115179380153266.\n",
      "[I 2025-07-09 16:48:40,224] Trial 2 finished with value: 0.4099238406247269 and parameters: {'max_depth': 6, 'min_child_weight': 1.593427122153146, 'subsample': 0.6440727996539968, 'colsample_bytree': 0.9547967638598068, 'lambda': 2.212515000441164, 'eta': 0.046541664776787166}. Best is trial 2 with value: 0.4099238406247269.\n",
      "[I 2025-07-09 16:49:58,364] Trial 3 finished with value: 0.41157148843029445 and parameters: {'max_depth': 12, 'min_child_weight': 1.224093047953132, 'subsample': 0.8002744587320613, 'colsample_bytree': 0.9750647502068228, 'lambda': 2.3799985023075516, 'eta': 0.06459309846458268}. Best is trial 2 with value: 0.4099238406247269.\n",
      "[I 2025-07-09 16:51:46,039] Trial 4 finished with value: 0.4105805931890546 and parameters: {'max_depth': 12, 'min_child_weight': 2.1985250118332513, 'subsample': 0.761706290336883, 'colsample_bytree': 0.8752049295510174, 'lambda': 6.723231084750746, 'eta': 0.04908261480571623}. Best is trial 2 with value: 0.4099238406247269.\n",
      "[I 2025-07-09 16:53:09,497] Trial 5 pruned. Trial was pruned at iteration 156.\n",
      "[I 2025-07-09 16:53:10,167] Trial 6 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-07-09 16:53:47,212] Trial 7 finished with value: 0.4112413412295352 and parameters: {'max_depth': 9, 'min_child_weight': 4.333159746892317, 'subsample': 0.7295464889457157, 'colsample_bytree': 0.8596620612545207, 'lambda': 4.188619108226963, 'eta': 0.21822126884966023}. Best is trial 2 with value: 0.4099238406247269.\n",
      "[I 2025-07-09 16:53:47,792] Trial 8 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-07-09 16:55:24,966] Trial 9 finished with value: 0.4114788995583472 and parameters: {'max_depth': 7, 'min_child_weight': 1.0128419250648237, 'subsample': 0.546131172923376, 'colsample_bytree': 0.8546971968626064, 'lambda': 5.291021407975452, 'eta': 0.10673661296072598}. Best is trial 2 with value: 0.4099238406247269.\n",
      "[I 2025-07-09 16:55:25,720] Trial 10 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-07-09 16:55:26,568] Trial 11 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-07-09 16:55:27,248] Trial 12 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-07-09 16:55:27,869] Trial 13 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-07-09 16:55:53,610] Trial 14 pruned. Trial was pruned at iteration 88.\n",
      "[I 2025-07-09 16:55:54,276] Trial 15 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-07-09 16:55:54,891] Trial 16 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-07-09 16:57:33,187] Trial 17 finished with value: 0.4097789016480817 and parameters: {'max_depth': 8, 'min_child_weight': 5.361891734274888, 'subsample': 0.9618841777880232, 'colsample_bytree': 0.6582241534026132, 'lambda': 3.3025003636212737, 'eta': 0.10167697633502167}. Best is trial 17 with value: 0.4097789016480817.\n",
      "[I 2025-07-09 16:58:12,483] Trial 18 finished with value: 0.41262615064429986 and parameters: {'max_depth': 8, 'min_child_weight': 6.000389747553954, 'subsample': 0.9447342964452043, 'colsample_bytree': 0.6285098329592018, 'lambda': 3.2325539023172905, 'eta': 0.2922977813893516}. Best is trial 17 with value: 0.4097789016480817.\n",
      "[I 2025-07-09 16:58:13,098] Trial 19 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-07-09 16:58:13,791] Trial 20 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-07-09 16:58:14,453] Trial 21 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-07-09 16:58:15,045] Trial 22 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-07-09 16:58:29,922] Trial 23 pruned. Trial was pruned at iteration 54.\n",
      "[I 2025-07-09 16:58:30,656] Trial 24 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-07-09 16:58:31,541] Trial 25 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-07-09 16:58:32,140] Trial 26 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-07-09 16:58:35,029] Trial 27 pruned. Trial was pruned at iteration 9.\n",
      "[I 2025-07-09 16:58:35,662] Trial 28 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-07-09 16:58:36,325] Trial 29 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-07-09 16:58:46,309] Trial 30 pruned. Trial was pruned at iteration 35.\n",
      "[I 2025-07-09 16:59:46,550] Trial 31 finished with value: 0.4113226477725462 and parameters: {'max_depth': 8, 'min_child_weight': 1.384639577344899, 'subsample': 0.6313650964912965, 'colsample_bytree': 0.7542603869698795, 'lambda': 6.852683816389075, 'eta': 0.1474652902555635}. Best is trial 17 with value: 0.4097789016480817.\n",
      "[I 2025-07-09 16:59:47,197] Trial 32 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-07-09 17:00:42,333] Trial 33 finished with value: 0.4131056015521584 and parameters: {'max_depth': 12, 'min_child_weight': 1.6884499469052678, 'subsample': 0.5628120948603821, 'colsample_bytree': 0.7566911929332866, 'lambda': 6.66886388043665, 'eta': 0.12024960851228077}. Best is trial 17 with value: 0.4097789016480817.\n",
      "[I 2025-07-09 17:02:08,641] Trial 34 finished with value: 0.411237949322671 and parameters: {'max_depth': 6, 'min_child_weight': 1.2173780863823336, 'subsample': 0.6215006047619013, 'colsample_bytree': 0.9849876074780786, 'lambda': 9.900645349334164, 'eta': 0.1707632473916267}. Best is trial 17 with value: 0.4097789016480817.\n",
      "[I 2025-07-09 17:02:09,287] Trial 35 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-07-09 17:02:09,892] Trial 36 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-07-09 17:02:10,512] Trial 37 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-07-09 17:02:44,910] Trial 38 finished with value: 0.41222705758136324 and parameters: {'max_depth': 10, 'min_child_weight': 1.060059493134961, 'subsample': 0.6980785692786748, 'colsample_bytree': 0.7739974854486869, 'lambda': 2.762806504240825, 'eta': 0.19949644836599525}. Best is trial 17 with value: 0.4097789016480817.\n",
      "[I 2025-07-09 17:02:55,273] Trial 39 pruned. Trial was pruned at iteration 37.\n",
      "[I 2025-07-09 17:02:55,937] Trial 40 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-07-09 17:03:09,078] Trial 41 pruned. Trial was pruned at iteration 45.\n",
      "[I 2025-07-09 17:05:47,492] Trial 42 finished with value: 0.41083554463220473 and parameters: {'max_depth': 6, 'min_child_weight': 1.8817813837360255, 'subsample': 0.6077326141090424, 'colsample_bytree': 0.976468433513786, 'lambda': 9.896288148735565, 'eta': 0.18417839392658109}. Best is trial 17 with value: 0.4097789016480817.\n",
      "[I 2025-07-09 17:06:39,802] Trial 43 finished with value: 0.41153974869648136 and parameters: {'max_depth': 7, 'min_child_weight': 1.8595590838687408, 'subsample': 0.5823544769391751, 'colsample_bytree': 0.9389392616310966, 'lambda': 9.170855714794635, 'eta': 0.24069233313028576}. Best is trial 17 with value: 0.4097789016480817.\n",
      "[I 2025-07-09 17:06:40,427] Trial 44 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-07-09 17:06:41,051] Trial 45 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-07-09 17:07:50,689] Trial 46 pruned. Trial was pruned at iteration 224.\n",
      "[I 2025-07-09 17:07:51,355] Trial 47 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-07-09 17:07:52,050] Trial 48 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-07-09 17:07:52,681] Trial 49 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-07-09 17:08:34,719] Trial 50 finished with value: 0.4119803183064314 and parameters: {'max_depth': 11, 'min_child_weight': 4.137393135297845, 'subsample': 0.5758374744071343, 'colsample_bytree': 0.8664482500118665, 'lambda': 3.83568528874388, 'eta': 0.14289357994224172}. Best is trial 17 with value: 0.4097789016480817.\n",
      "[I 2025-07-09 17:08:47,527] Trial 51 pruned. Trial was pruned at iteration 44.\n",
      "[I 2025-07-09 17:09:59,611] Trial 52 finished with value: 0.41048355035645906 and parameters: {'max_depth': 7, 'min_child_weight': 1.9588716577067324, 'subsample': 0.660390812940516, 'colsample_bytree': 0.9824965042517335, 'lambda': 9.52507521821257, 'eta': 0.1573285735907593}. Best is trial 17 with value: 0.4097789016480817.\n",
      "[I 2025-07-09 17:10:00,210] Trial 53 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-07-09 17:10:39,376] Trial 54 finished with value: 0.41193674659514307 and parameters: {'max_depth': 8, 'min_child_weight': 2.5745539503559267, 'subsample': 0.6893734096927173, 'colsample_bytree': 0.937292681389308, 'lambda': 8.372166212664375, 'eta': 0.24860762170240802}. Best is trial 17 with value: 0.4097789016480817.\n",
      "[I 2025-07-09 17:11:37,522] Trial 55 finished with value: 0.41087346791919094 and parameters: {'max_depth': 7, 'min_child_weight': 3.5114410243391285, 'subsample': 0.8148327730067757, 'colsample_bytree': 0.9102209898081011, 'lambda': 7.745551829090722, 'eta': 0.21707117095419753}. Best is trial 17 with value: 0.4097789016480817.\n",
      "[I 2025-07-09 17:12:41,348] Trial 56 finished with value: 0.41031219406604547 and parameters: {'max_depth': 7, 'min_child_weight': 3.7355076589601204, 'subsample': 0.8090484618345355, 'colsample_bytree': 0.9029233561320815, 'lambda': 9.520988350662355, 'eta': 0.2176878922606911}. Best is trial 17 with value: 0.4097789016480817.\n",
      "[I 2025-07-09 17:12:47,459] Trial 57 pruned. Trial was pruned at iteration 21.\n",
      "[I 2025-07-09 17:13:35,621] Trial 58 finished with value: 0.4111705410791882 and parameters: {'max_depth': 6, 'min_child_weight': 5.783485133944192, 'subsample': 0.8860239282972631, 'colsample_bytree': 0.9759369629748823, 'lambda': 0.685867145248551, 'eta': 0.2974990981985412}. Best is trial 17 with value: 0.4097789016480817.\n",
      "[I 2025-07-09 17:13:36,212] Trial 59 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-07-09 17:13:36,809] Trial 60 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-07-09 17:14:32,086] Trial 61 finished with value: 0.4107884449846328 and parameters: {'max_depth': 7, 'min_child_weight': 3.542069248402135, 'subsample': 0.8221262104752706, 'colsample_bytree': 0.9084091649208826, 'lambda': 7.7753362006942695, 'eta': 0.2201175989201871}. Best is trial 17 with value: 0.4097789016480817.\n",
      "[I 2025-07-09 17:15:29,336] Trial 62 finished with value: 0.4101818641671088 and parameters: {'max_depth': 7, 'min_child_weight': 6.276268443806629, 'subsample': 0.8403336166352231, 'colsample_bytree': 0.8967958232744623, 'lambda': 9.06633724524871, 'eta': 0.23466837131479587}. Best is trial 17 with value: 0.4097789016480817.\n",
      "[I 2025-07-09 17:16:25,113] Trial 63 finished with value: 0.41049312253052755 and parameters: {'max_depth': 7, 'min_child_weight': 7.300886332997254, 'subsample': 0.7957590592715271, 'colsample_bytree': 0.8840985839940521, 'lambda': 8.469254055885838, 'eta': 0.23200179028937695}. Best is trial 17 with value: 0.4097789016480817.\n",
      "[I 2025-07-09 17:17:05,467] Trial 64 finished with value: 0.41106189994466136 and parameters: {'max_depth': 8, 'min_child_weight': 6.461288716513045, 'subsample': 0.809283717032352, 'colsample_bytree': 0.8525237672274669, 'lambda': 9.11077189265071, 'eta': 0.25943826814457627}. Best is trial 17 with value: 0.4097789016480817.\n",
      "[I 2025-07-09 17:17:06,058] Trial 65 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-07-09 17:17:06,681] Trial 66 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-07-09 17:17:07,310] Trial 67 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-07-09 17:17:08,012] Trial 68 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-07-09 17:17:08,642] Trial 69 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-07-09 17:17:09,252] Trial 70 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-07-09 17:17:23,638] Trial 71 pruned. Trial was pruned at iteration 49.\n",
      "[I 2025-07-09 17:18:08,460] Trial 72 finished with value: 0.4113166090140642 and parameters: {'max_depth': 8, 'min_child_weight': 4.272422784117382, 'subsample': 0.8361275467925847, 'colsample_bytree': 0.8841024002525352, 'lambda': 8.599174971092287, 'eta': 0.22698656021750957}. Best is trial 17 with value: 0.4097789016480817.\n",
      "[I 2025-07-09 17:18:35,295] Trial 73 finished with value: 0.4138184076763103 and parameters: {'max_depth': 10, 'min_child_weight': 3.6108385574272934, 'subsample': 0.8120828265431407, 'colsample_bytree': 0.8671564306334495, 'lambda': 2.610936367245218, 'eta': 0.27830326196643596}. Best is trial 17 with value: 0.4097789016480817.\n",
      "[I 2025-07-09 17:18:38,648] Trial 74 pruned. Trial was pruned at iteration 10.\n",
      "[I 2025-07-09 17:18:39,295] Trial 75 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-07-09 17:18:39,886] Trial 76 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-07-09 17:18:40,536] Trial 77 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-07-09 17:18:44,573] Trial 78 pruned. Trial was pruned at iteration 13.\n",
      "[I 2025-07-09 17:18:49,164] Trial 79 pruned. Trial was pruned at iteration 15.\n",
      "[I 2025-07-09 17:18:49,793] Trial 80 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-07-09 17:18:50,487] Trial 81 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-07-09 17:18:51,104] Trial 82 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-07-09 17:18:51,828] Trial 83 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-07-09 17:18:52,417] Trial 84 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-07-09 17:19:32,388] Trial 85 finished with value: 0.4108487799148297 and parameters: {'max_depth': 8, 'min_child_weight': 5.179918848713336, 'subsample': 0.8048461791024403, 'colsample_bytree': 0.9624052218306421, 'lambda': 8.902388287471497, 'eta': 0.27559997066103326}. Best is trial 17 with value: 0.4097789016480817.\n",
      "[I 2025-07-09 17:19:33,017] Trial 86 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-07-09 17:20:19,969] Trial 87 finished with value: 0.4141413837052064 and parameters: {'max_depth': 12, 'min_child_weight': 1.7691288646492063, 'subsample': 0.5887581611415872, 'colsample_bytree': 0.9185775796406506, 'lambda': 8.283972030293818, 'eta': 0.24019290197957535}. Best is trial 17 with value: 0.4097789016480817.\n",
      "[I 2025-07-09 17:20:20,724] Trial 88 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-07-09 17:20:21,417] Trial 89 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-07-09 17:20:22,460] Trial 90 pruned. Trial was pruned at iteration 1.\n",
      "[I 2025-07-09 17:20:58,918] Trial 91 finished with value: 0.41139447981608007 and parameters: {'max_depth': 9, 'min_child_weight': 5.269094898859781, 'subsample': 0.7978081084568457, 'colsample_bytree': 0.9614933998789801, 'lambda': 8.982448953878272, 'eta': 0.27165443380110577}. Best is trial 17 with value: 0.4097789016480817.\n",
      "[I 2025-07-09 17:21:40,541] Trial 92 finished with value: 0.4112889632642526 and parameters: {'max_depth': 8, 'min_child_weight': 4.7338470669978, 'subsample': 0.8426012293817837, 'colsample_bytree': 0.8784818137088456, 'lambda': 8.829785273524267, 'eta': 0.2969359963977404}. Best is trial 17 with value: 0.4097789016480817.\n",
      "[I 2025-07-09 17:21:41,139] Trial 93 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-07-09 17:21:41,748] Trial 94 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-07-09 17:22:29,566] Trial 95 finished with value: 0.4109553561378697 and parameters: {'max_depth': 8, 'min_child_weight': 1.4746722656649942, 'subsample': 0.63950065314954, 'colsample_bytree': 0.9985429370809658, 'lambda': 8.126046415482845, 'eta': 0.21715101917152704}. Best is trial 17 with value: 0.4097789016480817.\n",
      "[I 2025-07-09 17:22:30,147] Trial 96 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-07-09 17:23:04,919] Trial 97 finished with value: 0.41109247169552926 and parameters: {'max_depth': 10, 'min_child_weight': 5.85324005368323, 'subsample': 0.7585148930501918, 'colsample_bytree': 0.9704983660058528, 'lambda': 9.254099843551163, 'eta': 0.23256052663015792}. Best is trial 17 with value: 0.4097789016480817.\n",
      "[I 2025-07-09 17:23:37,751] Trial 98 finished with value: 0.41051406779357447 and parameters: {'max_depth': 9, 'min_child_weight': 6.329073567721572, 'subsample': 0.9073081789543134, 'colsample_bytree': 0.9844349857005721, 'lambda': 4.121360153821633, 'eta': 0.2540802282623969}. Best is trial 17 with value: 0.4097789016480817.\n",
      "[I 2025-07-09 17:23:38,539] Trial 99 pruned. Trial was pruned at iteration 0.\n"
     ]
    }
   ],
   "source": [
    "# Create an Optuna study and optimize the objective function\n",
    "study = optuna.create_study(direction='minimize', sampler=optuna.samplers.TPESampler(seed=7))\n",
    "study.optimize(objective, n_trials=100, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T18:47:16.338521Z",
     "iopub.status.busy": "2025-01-22T18:47:16.338064Z",
     "iopub.status.idle": "2025-01-22T18:47:16.343580Z",
     "shell.execute_reply": "2025-01-22T18:47:16.343205Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters:  {'max_depth': 8, 'min_child_weight': 5.361891734274888, 'subsample': 0.9618841777880232, 'colsample_bytree': 0.6582241534026132, 'lambda': 3.3025003636212737, 'eta': 0.10167697633502167}\n",
      "Best loss:  0.4097789016480817\n"
     ]
    }
   ],
   "source": [
    "# Print the best hyperparameters and the best RMSE\n",
    "best_params = study.best_params\n",
    "best_loss = study.best_value\n",
    "print(\"Best Hyperparameters: \", best_params)\n",
    "print(\"Best loss: \", best_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrain the model with best hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best Hyperparameters:  \n",
    "{'max_depth': 8,   \n",
    "'min_child_weight': 5.361891734274888,   \n",
    "'subsample': 0.9618841777880232,   \n",
    "'colsample_bytree': 0.6582241534026132,   \n",
    "'lambda': 3.3025003636212737,   \n",
    "'eta': 0.10167697633502167}  \n",
    "Best loss:  0.4097789016480817"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-mlogloss:2.57191\tvalidation-mlogloss:2.58177\n",
      "[10]\ttrain-mlogloss:1.10607\tvalidation-mlogloss:1.11573\n",
      "[20]\ttrain-mlogloss:0.72497\tvalidation-mlogloss:0.73976\n",
      "[30]\ttrain-mlogloss:0.56771\tvalidation-mlogloss:0.58561\n",
      "[40]\ttrain-mlogloss:0.49389\tvalidation-mlogloss:0.51408\n",
      "[50]\ttrain-mlogloss:0.45366\tvalidation-mlogloss:0.47573\n",
      "[60]\ttrain-mlogloss:0.43069\tvalidation-mlogloss:0.45422\n",
      "[70]\ttrain-mlogloss:0.41629\tvalidation-mlogloss:0.44144\n",
      "[80]\ttrain-mlogloss:0.40691\tvalidation-mlogloss:0.43336\n",
      "[90]\ttrain-mlogloss:0.40055\tvalidation-mlogloss:0.42799\n",
      "[100]\ttrain-mlogloss:0.39579\tvalidation-mlogloss:0.42425\n",
      "[110]\ttrain-mlogloss:0.39185\tvalidation-mlogloss:0.42147\n",
      "[120]\ttrain-mlogloss:0.38866\tvalidation-mlogloss:0.41950\n",
      "[130]\ttrain-mlogloss:0.38579\tvalidation-mlogloss:0.41791\n",
      "[140]\ttrain-mlogloss:0.38313\tvalidation-mlogloss:0.41641\n",
      "[150]\ttrain-mlogloss:0.38058\tvalidation-mlogloss:0.41532\n",
      "[160]\ttrain-mlogloss:0.37838\tvalidation-mlogloss:0.41445\n",
      "[170]\ttrain-mlogloss:0.37633\tvalidation-mlogloss:0.41374\n",
      "[180]\ttrain-mlogloss:0.37417\tvalidation-mlogloss:0.41292\n",
      "[190]\ttrain-mlogloss:0.37191\tvalidation-mlogloss:0.41245\n",
      "[200]\ttrain-mlogloss:0.36982\tvalidation-mlogloss:0.41195\n",
      "[210]\ttrain-mlogloss:0.36787\tvalidation-mlogloss:0.41152\n",
      "[220]\ttrain-mlogloss:0.36610\tvalidation-mlogloss:0.41117\n",
      "[230]\ttrain-mlogloss:0.36434\tvalidation-mlogloss:0.41094\n",
      "[240]\ttrain-mlogloss:0.36276\tvalidation-mlogloss:0.41075\n",
      "[250]\ttrain-mlogloss:0.36123\tvalidation-mlogloss:0.41051\n",
      "[260]\ttrain-mlogloss:0.35971\tvalidation-mlogloss:0.41031\n",
      "[270]\ttrain-mlogloss:0.35834\tvalidation-mlogloss:0.41018\n",
      "[280]\ttrain-mlogloss:0.35696\tvalidation-mlogloss:0.41002\n",
      "[290]\ttrain-mlogloss:0.35570\tvalidation-mlogloss:0.40994\n",
      "[300]\ttrain-mlogloss:0.35439\tvalidation-mlogloss:0.40984\n",
      "[310]\ttrain-mlogloss:0.35324\tvalidation-mlogloss:0.40983\n",
      "[320]\ttrain-mlogloss:0.35201\tvalidation-mlogloss:0.40986\n",
      "[323]\ttrain-mlogloss:0.35161\tvalidation-mlogloss:0.40989\n"
     ]
    }
   ],
   "source": [
    "param = {\n",
    "        'objective': 'multi:softprob',\n",
    "        'eval_metric': 'mlogloss',\n",
    "        'num_class': num_act,\n",
    "        'max_depth': 8,\n",
    "        'min_child_weight': 5.361891734274888,\n",
    "        'subsample': 0.9618841777880232,\n",
    "        'colsample_bytree': 0.6582241534026132,\n",
    "        'lambda': 3.3025003636212737,\n",
    "        'eta': 0.10167697633502167\n",
    "    }\n",
    "\n",
    "dtrain = xgb.DMatrix(data=X_train, label=y_train)\n",
    "dvalid = xgb.DMatrix(data=X_val, label=y_val)\n",
    "\n",
    "model = xgb.train(param, \n",
    "                   dtrain, \n",
    "                   evals=[(dtrain, 'train'), (dvalid, 'validation')], \n",
    "                   num_boost_round = 100000,\n",
    "                   early_stopping_rounds=20,\n",
    "                   verbose_eval=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_model(\"xgb_20250621_1.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = xgb.Booster()\n",
    "model.load_model(\"xgb_20250621_1.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150877, 29)\n",
      "[7.4788336e-06 7.4788691e-06 7.4787977e-06 7.0097049e-06 7.4787476e-06\n",
      " 6.4275593e-01 8.4082894e-05 2.3697212e-01 1.1990678e-01 4.0533152e-05\n",
      " 7.6094493e-06 3.5545177e-06 1.3474127e-05 4.5101438e-06 7.3853821e-06\n",
      " 1.3625157e-05 8.2178321e-06 5.4330235e-06 5.8030305e-06 2.1547412e-05\n",
      " 4.5708689e-06 4.9924170e-06 1.3318877e-05 5.7432894e-06 1.1641090e-06\n",
      " 1.2536317e-05 1.1035225e-06 4.2435786e-05 2.6627506e-05]\n",
      "(150877,)\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "dvalid = xgb.DMatrix(X_val)\n",
    "\n",
    "preds = model.predict(dvalid)  # shape: (num_samples, num_class)\n",
    "print(preds.shape)\n",
    "print(preds[0])\n",
    "pred_labels = preds.argmax(axis=1)  # shape: (num_samples,)\n",
    "print(pred_labels.shape)\n",
    "print(pred_labels[0])\n",
    "pred_labels_tensor = torch.from_numpy(pred_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: tensor(0.844)\n",
      "Validation Macro Precision: tensor(0.778)\n",
      "Validation Macro Recall: tensor(0.723)\n",
      "Validation Macro F1 score: tensor(0.726)\n"
     ]
    }
   ],
   "source": [
    "accuracy, precision_macro, recall_macro, f1_macro = calculate_metrics(pred_labels_tensor, y_val_tensor, device, num_act)\n",
    "print('Validation Accuracy:', accuracy)\n",
    "print('Validation Macro Precision:', precision_macro)\n",
    "print('Validation Macro Recall:', recall_macro)\n",
    "print('Validation Macro F1 score:', f1_macro)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(241181, 29)\n",
      "[7.4788336e-06 7.4788691e-06 7.4787977e-06 7.0097049e-06 7.4787476e-06\n",
      " 6.4275593e-01 8.4082894e-05 2.3697212e-01 1.1990678e-01 4.0533152e-05\n",
      " 7.6094493e-06 3.5545177e-06 1.3474127e-05 4.5101438e-06 7.3853821e-06\n",
      " 1.3625157e-05 8.2178321e-06 5.4330235e-06 5.8030305e-06 2.1547412e-05\n",
      " 4.5708689e-06 4.9924170e-06 1.3318877e-05 5.7432894e-06 1.1641090e-06\n",
      " 1.2536317e-05 1.1035225e-06 4.2435786e-05 2.6627506e-05]\n",
      "(241181,)\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "dtest = xgb.DMatrix(X_test)\n",
    "\n",
    "preds = model.predict(dtest)  # shape: (num_samples, num_class)\n",
    "print(preds.shape)\n",
    "print(preds[0])\n",
    "pred_labels = preds.argmax(axis=1)  # shape: (num_samples,)\n",
    "print(pred_labels.shape)\n",
    "print(pred_labels[0])\n",
    "pred_labels_tensor = torch.from_numpy(pred_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: tensor(0.833)\n",
      "Test Macro Precision: tensor(0.781)\n",
      "Test Macro Recall: tensor(0.714)\n",
      "Test Macro F1 score: tensor(0.720)\n"
     ]
    }
   ],
   "source": [
    "accuracy, precision_macro, recall_macro, f1_macro = calculate_metrics(pred_labels_tensor, y_test_tensor, device, num_act)\n",
    "print('Test Accuracy:', accuracy)\n",
    "print('Test Macro Precision:', precision_macro)\n",
    "print('Test Macro Recall:', recall_macro)\n",
    "print('Test Macro F1 score:', f1_macro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_np = y_test_tensor.cpu().numpy()\n",
    "y_pred_np = pred_labels_tensor.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_dict = classification_report(y_true_np, y_pred_np, output_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.869969</td>\n",
       "      <td>0.910394</td>\n",
       "      <td>0.889723</td>\n",
       "      <td>7812.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.639579</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.780175</td>\n",
       "      <td>3707.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.989881</td>\n",
       "      <td>0.971391</td>\n",
       "      <td>0.980549</td>\n",
       "      <td>8459.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.826280</td>\n",
       "      <td>0.857477</td>\n",
       "      <td>0.841589</td>\n",
       "      <td>26936.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.999427</td>\n",
       "      <td>0.902708</td>\n",
       "      <td>0.948609</td>\n",
       "      <td>5797.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.797218</td>\n",
       "      <td>0.318136</td>\n",
       "      <td>0.454786</td>\n",
       "      <td>5944.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.914259</td>\n",
       "      <td>0.732545</td>\n",
       "      <td>0.813377</td>\n",
       "      <td>8035.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999381</td>\n",
       "      <td>0.999690</td>\n",
       "      <td>8073.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.797598</td>\n",
       "      <td>0.967098</td>\n",
       "      <td>0.874208</td>\n",
       "      <td>7416.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.888421</td>\n",
       "      <td>0.975183</td>\n",
       "      <td>0.929782</td>\n",
       "      <td>37232.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5948.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.941139</td>\n",
       "      <td>0.882295</td>\n",
       "      <td>0.910767</td>\n",
       "      <td>5038.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.708003</td>\n",
       "      <td>0.808919</td>\n",
       "      <td>0.755104</td>\n",
       "      <td>40004.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.838507</td>\n",
       "      <td>0.828010</td>\n",
       "      <td>0.833225</td>\n",
       "      <td>8547.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.849132</td>\n",
       "      <td>0.880364</td>\n",
       "      <td>0.864466</td>\n",
       "      <td>5057.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.397727</td>\n",
       "      <td>0.172414</td>\n",
       "      <td>0.240550</td>\n",
       "      <td>406.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.797281</td>\n",
       "      <td>0.772141</td>\n",
       "      <td>0.784509</td>\n",
       "      <td>38278.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.865920</td>\n",
       "      <td>0.802634</td>\n",
       "      <td>0.833077</td>\n",
       "      <td>5391.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.364865</td>\n",
       "      <td>0.012956</td>\n",
       "      <td>0.025023</td>\n",
       "      <td>2084.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.193548</td>\n",
       "      <td>0.022693</td>\n",
       "      <td>0.040623</td>\n",
       "      <td>3966.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4079.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.005252</td>\n",
       "      <td>0.010081</td>\n",
       "      <td>952.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.996596</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998295</td>\n",
       "      <td>1171.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.724466</td>\n",
       "      <td>0.727056</td>\n",
       "      <td>0.725758</td>\n",
       "      <td>839.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>10.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.833030</td>\n",
       "      <td>0.833030</td>\n",
       "      <td>0.833030</td>\n",
       "      <td>0.83303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.780993</td>\n",
       "      <td>0.713962</td>\n",
       "      <td>0.719820</td>\n",
       "      <td>241181.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.821264</td>\n",
       "      <td>0.833030</td>\n",
       "      <td>0.819528</td>\n",
       "      <td>241181.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score       support\n",
       "3              0.869969  0.910394  0.889723    7812.00000\n",
       "5              0.639579  1.000000  0.780175    3707.00000\n",
       "6              0.989881  0.971391  0.980549    8459.00000\n",
       "7              0.826280  0.857477  0.841589   26936.00000\n",
       "8              0.999427  0.902708  0.948609    5797.00000\n",
       "9              0.797218  0.318136  0.454786    5944.00000\n",
       "10             0.914259  0.732545  0.813377    8035.00000\n",
       "11             1.000000  0.999381  0.999690    8073.00000\n",
       "12             0.797598  0.967098  0.874208    7416.00000\n",
       "13             0.888421  0.975183  0.929782   37232.00000\n",
       "14             1.000000  1.000000  1.000000    5948.00000\n",
       "15             0.941139  0.882295  0.910767    5038.00000\n",
       "16             0.708003  0.808919  0.755104   40004.00000\n",
       "17             0.838507  0.828010  0.833225    8547.00000\n",
       "18             0.849132  0.880364  0.864466    5057.00000\n",
       "19             0.397727  0.172414  0.240550     406.00000\n",
       "20             0.797281  0.772141  0.784509   38278.00000\n",
       "21             0.865920  0.802634  0.833077    5391.00000\n",
       "22             0.364865  0.012956  0.025023    2084.00000\n",
       "23             0.193548  0.022693  0.040623    3966.00000\n",
       "24             1.000000  1.000000  1.000000    4079.00000\n",
       "25             0.125000  0.005252  0.010081     952.00000\n",
       "26             0.996596  1.000000  0.998295    1171.00000\n",
       "27             0.724466  0.727056  0.725758     839.00000\n",
       "28             1.000000  0.300000  0.461538      10.00000\n",
       "accuracy       0.833030  0.833030  0.833030       0.83303\n",
       "macro avg      0.780993  0.713962  0.719820  241181.00000\n",
       "weighted avg   0.821264  0.833030  0.819528  241181.00000"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert to DataFrame for tabular view\n",
    "report_df = pd.DataFrame(report_dict).transpose()\n",
    "report_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    precision    recall  f1-score\n",
      "3    0.869969  0.910394  0.889723\n",
      "5    0.639579  1.000000  0.780175\n",
      "6    0.989881  0.971391  0.980549\n",
      "7    0.826280  0.857477  0.841589\n",
      "8    0.999427  0.902708  0.948609\n",
      "9    0.797218  0.318136  0.454786\n",
      "10   0.914259  0.732545  0.813377\n",
      "11   1.000000  0.999381  0.999690\n",
      "12   0.797598  0.967098  0.874208\n",
      "13   0.888421  0.975183  0.929782\n",
      "14   1.000000  1.000000  1.000000\n",
      "15   0.941139  0.882295  0.910767\n",
      "16   0.708003  0.808919  0.755104\n",
      "17   0.838507  0.828010  0.833225\n",
      "18   0.849132  0.880364  0.864466\n",
      "19   0.397727  0.172414  0.240550\n",
      "20   0.797281  0.772141  0.784509\n",
      "21   0.865920  0.802634  0.833077\n",
      "22   0.364865  0.012956  0.025023\n",
      "23   0.193548  0.022693  0.040623\n",
      "24   1.000000  1.000000  1.000000\n",
      "25   0.125000  0.005252  0.010081\n",
      "26   0.996596  1.000000  0.998295\n",
      "27   0.724466  0.727056  0.725758\n",
      "28   1.000000  0.300000  0.461538\n"
     ]
    }
   ],
   "source": [
    "# Only keep rows for actual class labels (exclude \"accuracy\", \"macro avg\", etc.)\n",
    "report_df = report_df[report_df.index.str.isdigit()]\n",
    "\n",
    "# Display the result\n",
    "print(report_df[['precision', 'recall', 'f1-score']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_240567/3649599814.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  report_df['support (%)'] = 100.0 * report_df['support'] / total_support\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "      <th>support (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.869969</td>\n",
       "      <td>0.910394</td>\n",
       "      <td>0.889723</td>\n",
       "      <td>7812.0</td>\n",
       "      <td>3.239061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.639579</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.780175</td>\n",
       "      <td>3707.0</td>\n",
       "      <td>1.537020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.989881</td>\n",
       "      <td>0.971391</td>\n",
       "      <td>0.980549</td>\n",
       "      <td>8459.0</td>\n",
       "      <td>3.507324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.826280</td>\n",
       "      <td>0.857477</td>\n",
       "      <td>0.841589</td>\n",
       "      <td>26936.0</td>\n",
       "      <td>11.168376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.999427</td>\n",
       "      <td>0.902708</td>\n",
       "      <td>0.948609</td>\n",
       "      <td>5797.0</td>\n",
       "      <td>2.403589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.797218</td>\n",
       "      <td>0.318136</td>\n",
       "      <td>0.454786</td>\n",
       "      <td>5944.0</td>\n",
       "      <td>2.464539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.914259</td>\n",
       "      <td>0.732545</td>\n",
       "      <td>0.813377</td>\n",
       "      <td>8035.0</td>\n",
       "      <td>3.331523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999381</td>\n",
       "      <td>0.999690</td>\n",
       "      <td>8073.0</td>\n",
       "      <td>3.347279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.797598</td>\n",
       "      <td>0.967098</td>\n",
       "      <td>0.874208</td>\n",
       "      <td>7416.0</td>\n",
       "      <td>3.074869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.888421</td>\n",
       "      <td>0.975183</td>\n",
       "      <td>0.929782</td>\n",
       "      <td>37232.0</td>\n",
       "      <td>15.437369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5948.0</td>\n",
       "      <td>2.466198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.941139</td>\n",
       "      <td>0.882295</td>\n",
       "      <td>0.910767</td>\n",
       "      <td>5038.0</td>\n",
       "      <td>2.088888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.708003</td>\n",
       "      <td>0.808919</td>\n",
       "      <td>0.755104</td>\n",
       "      <td>40004.0</td>\n",
       "      <td>16.586713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.838507</td>\n",
       "      <td>0.828010</td>\n",
       "      <td>0.833225</td>\n",
       "      <td>8547.0</td>\n",
       "      <td>3.543811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.849132</td>\n",
       "      <td>0.880364</td>\n",
       "      <td>0.864466</td>\n",
       "      <td>5057.0</td>\n",
       "      <td>2.096765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.397727</td>\n",
       "      <td>0.172414</td>\n",
       "      <td>0.240550</td>\n",
       "      <td>406.0</td>\n",
       "      <td>0.168338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.797281</td>\n",
       "      <td>0.772141</td>\n",
       "      <td>0.784509</td>\n",
       "      <td>38278.0</td>\n",
       "      <td>15.871068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.865920</td>\n",
       "      <td>0.802634</td>\n",
       "      <td>0.833077</td>\n",
       "      <td>5391.0</td>\n",
       "      <td>2.235251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.364865</td>\n",
       "      <td>0.012956</td>\n",
       "      <td>0.025023</td>\n",
       "      <td>2084.0</td>\n",
       "      <td>0.864081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.193548</td>\n",
       "      <td>0.022693</td>\n",
       "      <td>0.040623</td>\n",
       "      <td>3966.0</td>\n",
       "      <td>1.644408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4079.0</td>\n",
       "      <td>1.691261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.005252</td>\n",
       "      <td>0.010081</td>\n",
       "      <td>952.0</td>\n",
       "      <td>0.394724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.996596</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998295</td>\n",
       "      <td>1171.0</td>\n",
       "      <td>0.485527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.724466</td>\n",
       "      <td>0.727056</td>\n",
       "      <td>0.725758</td>\n",
       "      <td>839.0</td>\n",
       "      <td>0.347872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.004146</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    precision    recall  f1-score  support  support (%)\n",
       "3    0.869969  0.910394  0.889723   7812.0     3.239061\n",
       "5    0.639579  1.000000  0.780175   3707.0     1.537020\n",
       "6    0.989881  0.971391  0.980549   8459.0     3.507324\n",
       "7    0.826280  0.857477  0.841589  26936.0    11.168376\n",
       "8    0.999427  0.902708  0.948609   5797.0     2.403589\n",
       "9    0.797218  0.318136  0.454786   5944.0     2.464539\n",
       "10   0.914259  0.732545  0.813377   8035.0     3.331523\n",
       "11   1.000000  0.999381  0.999690   8073.0     3.347279\n",
       "12   0.797598  0.967098  0.874208   7416.0     3.074869\n",
       "13   0.888421  0.975183  0.929782  37232.0    15.437369\n",
       "14   1.000000  1.000000  1.000000   5948.0     2.466198\n",
       "15   0.941139  0.882295  0.910767   5038.0     2.088888\n",
       "16   0.708003  0.808919  0.755104  40004.0    16.586713\n",
       "17   0.838507  0.828010  0.833225   8547.0     3.543811\n",
       "18   0.849132  0.880364  0.864466   5057.0     2.096765\n",
       "19   0.397727  0.172414  0.240550    406.0     0.168338\n",
       "20   0.797281  0.772141  0.784509  38278.0    15.871068\n",
       "21   0.865920  0.802634  0.833077   5391.0     2.235251\n",
       "22   0.364865  0.012956  0.025023   2084.0     0.864081\n",
       "23   0.193548  0.022693  0.040623   3966.0     1.644408\n",
       "24   1.000000  1.000000  1.000000   4079.0     1.691261\n",
       "25   0.125000  0.005252  0.010081    952.0     0.394724\n",
       "26   0.996596  1.000000  0.998295   1171.0     0.485527\n",
       "27   0.724466  0.727056  0.725758    839.0     0.347872\n",
       "28   1.000000  0.300000  0.461538     10.0     0.004146"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_support = report_df['support'].sum()\n",
    "report_df['support (%)'] = 100.0 * report_df['support'] / total_support\n",
    "report_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "079f94be53604e869c0af824f20a3d1f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_397d6fd34b764ef3b72e30d627d41148",
        "IPY_MODEL_281431f12fef41bd89cc0ab6d6369f3c",
        "IPY_MODEL_eb24d11920454a6093eebc542b354798"
       ],
       "layout": "IPY_MODEL_b8e8895c4e394918bbfad2e82856b19f",
       "tabbable": null,
       "tooltip": null
      }
     },
     "099dec27c437499c94f7ca338049b01c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "0a89b82639a14267903cee31c61a4f82": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_b946c7d8176c4bcabc6d2a7b1f2dda8d",
        "IPY_MODEL_ebbcdbee147d44c78687c5311834d97a",
        "IPY_MODEL_d9e3350521e245b98e1e59db6d6f7750"
       ],
       "layout": "IPY_MODEL_dc9ac9e4529141cea190e5ef9d0218b9",
       "tabbable": null,
       "tooltip": null
      }
     },
     "0aa3290588924cdbb30ec92c6f6d8e93": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "0b7752a227734891934ded04bb3db0df": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "12d195777e8a417681e1f1b2930ac3ee": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1ad07903b6634f3e8f70ef9fc9ecf28d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_0aa3290588924cdbb30ec92c6f6d8e93",
       "max": 100,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_396e4a01daa449b38075102e46005855",
       "tabbable": null,
       "tooltip": null,
       "value": 100
      }
     },
     "2547298e7d2c441e9f51d972a08b190e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "281431f12fef41bd89cc0ab6d6369f3c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_2547298e7d2c441e9f51d972a08b190e",
       "max": 100,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_b65a51eca7c14563a68275641c636bdd",
       "tabbable": null,
       "tooltip": null,
       "value": 100
      }
     },
     "396e4a01daa449b38075102e46005855": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "397d6fd34b764ef3b72e30d627d41148": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_12d195777e8a417681e1f1b2930ac3ee",
       "placeholder": "",
       "style": "IPY_MODEL_de23d77f5d714a119b4e06f6dba27839",
       "tabbable": null,
       "tooltip": null,
       "value": "Besttrial:89.Bestvalue:0.0398459:100%"
      }
     },
     "4fd91a26e5254148995bbac991b6a3de": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "55d0adfb62784cbb8fdd101773bf25f0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "61683c1af8a447e7924f4dc1435aedd5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_9e355a550eb1475b8eaa127d1dbef1cb",
       "placeholder": "",
       "style": "IPY_MODEL_7ae2dd5f14614d01958468e3ecded17f",
       "tabbable": null,
       "tooltip": null,
       "value": "100/100[2:50:58&lt;00:00,44.09s/it]"
      }
     },
     "6516ea8bb7ed4b4a93d05405462b7d06": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_c81dec35bf6d407eaf4c3c45adef8f9a",
        "IPY_MODEL_1ad07903b6634f3e8f70ef9fc9ecf28d",
        "IPY_MODEL_61683c1af8a447e7924f4dc1435aedd5"
       ],
       "layout": "IPY_MODEL_9397555ad36143b8812e36a58322cd88",
       "tabbable": null,
       "tooltip": null
      }
     },
     "7ae2dd5f14614d01958468e3ecded17f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "7afc78b1f0a244b68165b0a8b67f1a87": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "88d437c8e41143a7af560426089d2f86": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "8cb7dd9796d442758827c1066aa6d12b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9397555ad36143b8812e36a58322cd88": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9e355a550eb1475b8eaa127d1dbef1cb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a8110a59a1c2470a96a31551e8248b12": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "b65a51eca7c14563a68275641c636bdd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "b8e8895c4e394918bbfad2e82856b19f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b946c7d8176c4bcabc6d2a7b1f2dda8d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_55d0adfb62784cbb8fdd101773bf25f0",
       "placeholder": "",
       "style": "IPY_MODEL_7afc78b1f0a244b68165b0a8b67f1a87",
       "tabbable": null,
       "tooltip": null,
       "value": "Besttrial:43.Bestvalue:0.0649812:100%"
      }
     },
     "c1843c14a5cc4afc9df084013cdf5ac9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c81dec35bf6d407eaf4c3c45adef8f9a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_099dec27c437499c94f7ca338049b01c",
       "placeholder": "",
       "style": "IPY_MODEL_a8110a59a1c2470a96a31551e8248b12",
       "tabbable": null,
       "tooltip": null,
       "value": "Besttrial:22.Bestvalue:0.64837:100%"
      }
     },
     "d9e3350521e245b98e1e59db6d6f7750": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_8cb7dd9796d442758827c1066aa6d12b",
       "placeholder": "",
       "style": "IPY_MODEL_0b7752a227734891934ded04bb3db0df",
       "tabbable": null,
       "tooltip": null,
       "value": "100/100[23:53&lt;00:00,4.97s/it]"
      }
     },
     "dc9ac9e4529141cea190e5ef9d0218b9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "de23d77f5d714a119b4e06f6dba27839": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "eb24d11920454a6093eebc542b354798": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_c1843c14a5cc4afc9df084013cdf5ac9",
       "placeholder": "",
       "style": "IPY_MODEL_88d437c8e41143a7af560426089d2f86",
       "tabbable": null,
       "tooltip": null,
       "value": "100/100[38:12&lt;00:00,7.16s/it]"
      }
     },
     "ebbcdbee147d44c78687c5311834d97a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_4fd91a26e5254148995bbac991b6a3de",
       "max": 100,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_fee48b20b2e14376885620049c5e5e11",
       "tabbable": null,
       "tooltip": null,
       "value": 100
      }
     },
     "fee48b20b2e14376885620049c5e5e11": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
