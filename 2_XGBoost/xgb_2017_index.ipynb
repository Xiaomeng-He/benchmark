{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Documentation\n",
    "\n",
    "index one-hot encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-21T17:23:59.088107Z",
     "iopub.status.busy": "2025-06-21T17:23:59.087733Z",
     "iopub.status.idle": "2025-06-21T17:24:28.764345Z",
     "shell.execute_reply": "2025-06-21T17:24:28.763759Z"
    }
   },
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import csv\n",
    "import optuna\n",
    "import xgboost as xgb\n",
    "from optuna.integration import XGBoostPruningCallback\n",
    "from train_evaluate import calculate_metrics\n",
    "from ensemble_encode import index_encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-21T17:24:28.767529Z",
     "iopub.status.busy": "2025-06-21T17:24:28.766995Z",
     "iopub.status.idle": "2025-06-21T17:24:28.769843Z",
     "shell.execute_reply": "2025-06-21T17:24:28.769460Z"
    }
   },
   "outputs": [],
   "source": [
    "num_act = 29\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-21T17:24:28.771807Z",
     "iopub.status.busy": "2025-06-21T17:24:28.771547Z",
     "iopub.status.idle": "2025-06-21T17:24:28.773840Z",
     "shell.execute_reply": "2025-06-21T17:24:28.773466Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set printed tensor format\n",
    "torch.set_printoptions(sci_mode=False, precision=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-21T17:24:28.775755Z",
     "iopub.status.busy": "2025-06-21T17:24:28.775444Z",
     "iopub.status.idle": "2025-06-21T17:24:28.778306Z",
     "shell.execute_reply": "2025-06-21T17:24:28.777918Z"
    }
   },
   "outputs": [],
   "source": [
    "# define file path\n",
    "train_prefix_act_tensor_path = '/scratch/leuven/370/vsc37039/tensor_2017_0616/train_prefix_act_0616_l.pt'\n",
    "train_prefix_time_tensor_path = '/scratch/leuven/370/vsc37039/tensor_2017_0616/train_prefix_time_0616_l.pt'\n",
    "train_suffix_act_tensor_path = '/scratch/leuven/370/vsc37039/tensor_2017_0616/train_suffix_act_0616.pt'\n",
    "\n",
    "val_prefix_act_tensor_path = '/scratch/leuven/370/vsc37039/tensor_2017_0616/val_prefix_act_0616_l.pt'\n",
    "val_prefix_time_tensor_path = '/scratch/leuven/370/vsc37039/tensor_2017_0616/val_prefix_time_0616_l.pt'\n",
    "val_suffix_act_tensor_path = '/scratch/leuven/370/vsc37039/tensor_2017_0616/val_suffix_act_0616.pt'\n",
    "\n",
    "test_prefix_act_tensor_path = '/scratch/leuven/370/vsc37039/tensor_2017_0616/test_prefix_act_0616_l.pt'\n",
    "test_prefix_time_tensor_path = '/scratch/leuven/370/vsc37039/tensor_2017_0616/test_prefix_time_0616_l.pt'\n",
    "test_suffix_act_tensor_path = '/scratch/leuven/370/vsc37039/tensor_2017_0616/test_suffix_act_0616.pt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-21T17:24:28.780264Z",
     "iopub.status.busy": "2025-06-21T17:24:28.779943Z",
     "iopub.status.idle": "2025-06-21T17:24:29.646118Z",
     "shell.execute_reply": "2025-06-21T17:24:29.645674Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1507625/55898070.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  train_prefix_act_tensor = torch.load(train_prefix_act_tensor_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([630994, 87])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1507625/55898070.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  train_prefix_time_tensor = torch.load(train_prefix_time_tensor_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([630994, 87, 2])\n"
     ]
    }
   ],
   "source": [
    "train_prefix_act_tensor = torch.load(train_prefix_act_tensor_path)\n",
    "print(train_prefix_act_tensor.shape)\n",
    "\n",
    "train_prefix_time_tensor = torch.load(train_prefix_time_tensor_path)\n",
    "print(train_prefix_time_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-21T17:24:29.648419Z",
     "iopub.status.busy": "2025-06-21T17:24:29.648001Z",
     "iopub.status.idle": "2025-06-21T17:24:29.671390Z",
     "shell.execute_reply": "2025-06-21T17:24:29.670978Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 5])\n",
      "tensor([[-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [     0.000,      0.000],\n",
      "        [     0.003,      0.003]])\n"
     ]
    }
   ],
   "source": [
    "print(train_prefix_act_tensor[1])\n",
    "print(train_prefix_time_tensor[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-21T17:24:29.673458Z",
     "iopub.status.busy": "2025-06-21T17:24:29.673234Z",
     "iopub.status.idle": "2025-06-21T17:24:31.343200Z",
     "shell.execute_reply": "2025-06-21T17:24:31.342757Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(630994, 2697)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = index_encode(train_prefix_act_tensor, train_prefix_time_tensor, num_act)\n",
    "print(X_train.shape)\n",
    "type(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-21T17:24:31.345670Z",
     "iopub.status.busy": "2025-06-21T17:24:31.345306Z",
     "iopub.status.idle": "2025-06-21T17:24:31.349421Z",
     "shell.execute_reply": "2025-06-21T17:24:31.349055Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 0.        , 0.        , ..., 0.        , 0.0030776 ,\n",
       "       0.00316715], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## X_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-21T17:24:31.352625Z",
     "iopub.status.busy": "2025-06-21T17:24:31.351655Z",
     "iopub.status.idle": "2025-06-21T17:24:31.667679Z",
     "shell.execute_reply": "2025-06-21T17:24:31.667226Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1507625/2509626994.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  val_prefix_act_tensor = torch.load(val_prefix_act_tensor_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([150877, 87])\n",
      "torch.Size([150877, 87, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1507625/2509626994.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  val_prefix_time_tensor = torch.load(val_prefix_time_tensor_path)\n"
     ]
    }
   ],
   "source": [
    "val_prefix_act_tensor = torch.load(val_prefix_act_tensor_path)\n",
    "print(val_prefix_act_tensor.shape)\n",
    "\n",
    "val_prefix_time_tensor = torch.load(val_prefix_time_tensor_path)\n",
    "print(val_prefix_time_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-21T17:24:31.669973Z",
     "iopub.status.busy": "2025-06-21T17:24:31.669559Z",
     "iopub.status.idle": "2025-06-21T17:24:31.675996Z",
     "shell.execute_reply": "2025-06-21T17:24:31.675601Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 5])\n",
      "tensor([[-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [     0.000,      0.000],\n",
      "        [     0.003,      0.003]])\n"
     ]
    }
   ],
   "source": [
    "print(val_prefix_act_tensor[1])\n",
    "print(val_prefix_time_tensor[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-21T17:24:31.677939Z",
     "iopub.status.busy": "2025-06-21T17:24:31.677614Z",
     "iopub.status.idle": "2025-06-21T17:24:32.109965Z",
     "shell.execute_reply": "2025-06-21T17:24:32.109570Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150877, 2697)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val = index_encode(val_prefix_act_tensor, val_prefix_time_tensor, num_act)\n",
    "print(X_val.shape)\n",
    "type(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-21T17:24:32.112422Z",
     "iopub.status.busy": "2025-06-21T17:24:32.112059Z",
     "iopub.status.idle": "2025-06-21T17:24:32.115585Z",
     "shell.execute_reply": "2025-06-21T17:24:32.115226Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 0.        , 0.        , ..., 0.        , 0.00276367,\n",
       "       0.00284408], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-21T17:24:32.117650Z",
     "iopub.status.busy": "2025-06-21T17:24:32.117334Z",
     "iopub.status.idle": "2025-06-21T17:24:32.554941Z",
     "shell.execute_reply": "2025-06-21T17:24:32.554507Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1507625/3558777084.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  test_prefix_act_tensor = torch.load(test_prefix_act_tensor_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([241181, 87])\n",
      "torch.Size([241181, 87, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1507625/3558777084.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  test_prefix_time_tensor = torch.load(test_prefix_time_tensor_path)\n"
     ]
    }
   ],
   "source": [
    "test_prefix_act_tensor = torch.load(test_prefix_act_tensor_path)\n",
    "print(test_prefix_act_tensor.shape)\n",
    "\n",
    "test_prefix_time_tensor = torch.load(test_prefix_time_tensor_path)\n",
    "print(test_prefix_time_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-21T17:24:32.557035Z",
     "iopub.status.busy": "2025-06-21T17:24:32.556699Z",
     "iopub.status.idle": "2025-06-21T17:24:32.562770Z",
     "shell.execute_reply": "2025-06-21T17:24:32.562374Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 8])\n",
      "tensor([[-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [-10000.000, -10000.000],\n",
      "        [     0.000,      0.000],\n",
      "        [     0.000,      0.000]])\n"
     ]
    }
   ],
   "source": [
    "print(test_prefix_act_tensor[1])\n",
    "print(test_prefix_time_tensor[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-21T17:24:32.564608Z",
     "iopub.status.busy": "2025-06-21T17:24:32.564356Z",
     "iopub.status.idle": "2025-06-21T17:24:33.146748Z",
     "shell.execute_reply": "2025-06-21T17:24:33.146352Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(241181, 2697)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = index_encode(test_prefix_act_tensor, test_prefix_time_tensor, num_act)\n",
    "print(X_test.shape)\n",
    "type(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-21T17:24:33.149070Z",
     "iopub.status.busy": "2025-06-21T17:24:33.148601Z",
     "iopub.status.idle": "2025-06-21T17:24:33.152247Z",
     "shell.execute_reply": "2025-06-21T17:24:33.151883Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.0000000e+00, 0.0000000e+00, 0.0000000e+00, ..., 0.0000000e+00,\n",
       "       1.3115592e-04, 1.3497197e-04], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-21T17:24:33.154401Z",
     "iopub.status.busy": "2025-06-21T17:24:33.154060Z",
     "iopub.status.idle": "2025-06-21T17:24:33.567723Z",
     "shell.execute_reply": "2025-06-21T17:24:33.567321Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1507625/296722895.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  train_suffix_act_tensor = torch.load(train_suffix_act_tensor_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([630994, 87])\n",
      "torch.Size([630994])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_suffix_act_tensor = torch.load(train_suffix_act_tensor_path)\n",
    "print(train_suffix_act_tensor.shape)\n",
    "\n",
    "y_train_tensor = train_suffix_act_tensor[:, 0]\n",
    "print(y_train_tensor.shape)\n",
    "\n",
    "y_train = y_train_tensor.numpy()\n",
    "type(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-21T17:24:33.569908Z",
     "iopub.status.busy": "2025-06-21T17:24:33.569567Z",
     "iopub.status.idle": "2025-06-21T17:24:33.572737Z",
     "shell.execute_reply": "2025-06-21T17:24:33.572376Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-21T17:24:33.574671Z",
     "iopub.status.busy": "2025-06-21T17:24:33.574404Z",
     "iopub.status.idle": "2025-06-21T17:24:33.735620Z",
     "shell.execute_reply": "2025-06-21T17:24:33.735223Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1507625/3081499601.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  val_suffix_act_tensor = torch.load(val_suffix_act_tensor_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([150877, 87])\n",
      "torch.Size([150877])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_suffix_act_tensor = torch.load(val_suffix_act_tensor_path)\n",
    "print(val_suffix_act_tensor.shape)\n",
    "\n",
    "y_val_tensor = val_suffix_act_tensor[:, 0]\n",
    "print(y_val_tensor.shape)\n",
    "\n",
    "y_val = y_val_tensor.numpy()\n",
    "type(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-21T17:24:33.738307Z",
     "iopub.status.busy": "2025-06-21T17:24:33.737911Z",
     "iopub.status.idle": "2025-06-21T17:24:33.741004Z",
     "shell.execute_reply": "2025-06-21T17:24:33.740648Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-21T17:24:33.742948Z",
     "iopub.status.busy": "2025-06-21T17:24:33.742685Z",
     "iopub.status.idle": "2025-06-21T17:24:33.944246Z",
     "shell.execute_reply": "2025-06-21T17:24:33.943834Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1507625/515295135.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  test_suffix_act_tensor = torch.load(test_suffix_act_tensor_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([241181, 87])\n",
      "torch.Size([241181])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_suffix_act_tensor = torch.load(test_suffix_act_tensor_path)\n",
    "print(test_suffix_act_tensor.shape)\n",
    "\n",
    "y_test_tensor = test_suffix_act_tensor[:, 0]\n",
    "print(y_test_tensor.shape)\n",
    "\n",
    "y_test = y_test_tensor.numpy()\n",
    "type(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-21T17:24:33.946532Z",
     "iopub.status.busy": "2025-06-21T17:24:33.946142Z",
     "iopub.status.idle": "2025-06-21T17:24:33.949216Z",
     "shell.execute_reply": "2025-06-21T17:24:33.948862Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-21T17:24:33.951072Z",
     "iopub.status.busy": "2025-06-21T17:24:33.950808Z",
     "iopub.status.idle": "2025-06-21T17:24:33.954887Z",
     "shell.execute_reply": "2025-06-21T17:24:33.954510Z"
    }
   },
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    # Define the search space for hyperparameters\n",
    "    param = {\n",
    "        'objective': 'multi:softprob',\n",
    "        'eval_metric': 'mlogloss',\n",
    "        'num_class': num_act,\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 12),\n",
    "        'min_child_weight': trial.suggest_float('min_child_weight', 1, 10.0),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "        'lambda': trial.suggest_float('lambda', 0.1, 10.0),\n",
    "        'eta': trial.suggest_float('eta', 0.01, 0.3, log=True)\n",
    "    }\n",
    "\n",
    "    # Convert the data into DMatrix format\n",
    "    dtrain = xgb.DMatrix(data=X_train, label=y_train)\n",
    "    dvalid = xgb.DMatrix(data=X_val, label=y_val)\n",
    "\n",
    "    # Define the pruning callback for early stopping\n",
    "    pruning_callback = optuna.integration.XGBoostPruningCallback(trial, 'validation-mlogloss')\n",
    "\n",
    "    # Train the model with early stopping\n",
    "    model = xgb.train(param, \n",
    "                      dtrain, \n",
    "                      evals=[(dvalid, 'validation')], \n",
    "                      num_boost_round = 100000, \n",
    "                      early_stopping_rounds=20, \n",
    "                      callbacks=[pruning_callback],\n",
    "                      verbose_eval=False)\n",
    "\n",
    "    return model.best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-21T17:24:33.956653Z",
     "iopub.status.busy": "2025-06-21T17:24:33.956401Z",
     "iopub.status.idle": "2025-06-22T16:02:54.154803Z",
     "shell.execute_reply": "2025-06-22T16:02:54.154117Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-21 19:24:33,958] A new study created in memory with name: no-name-16f7cd53-ae62-42aa-83ad-630ddf19c70c\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abea5e72b1d04f36bc571ceac1de351a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-21 23:43:47,520] Trial 0 finished with value: 0.29281825491937435 and parameters: {'max_depth': 3, 'min_child_weight': 8.019269130161032, 'subsample': 0.7192046157204468, 'colsample_bytree': 0.8617325889154706, 'lambda': 9.782096168766367, 'eta': 0.062434364533734486}. Best is trial 0 with value: 0.29281825491937435.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 00:15:10,985] Trial 1 finished with value: 0.29304800637353273 and parameters: {'max_depth': 8, 'min_child_weight': 1.648460200237854, 'subsample': 0.6342194900509356, 'colsample_bytree': 0.74994125041278, 'lambda': 6.82437696159731, 'eta': 0.153893406647721}. Best is trial 0 with value: 0.29281825491937435.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 02:37:14,880] Trial 2 finished with value: 0.289645412499421 and parameters: {'max_depth': 6, 'min_child_weight': 1.593427122153146, 'subsample': 0.6440727996539968, 'colsample_bytree': 0.9547967638598068, 'lambda': 2.212515000441164, 'eta': 0.046541664776787166}. Best is trial 2 with value: 0.289645412499421.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 03:15:34,299] Trial 3 finished with value: 0.2907469851373043 and parameters: {'max_depth': 12, 'min_child_weight': 1.224093047953132, 'subsample': 0.8002744587320613, 'colsample_bytree': 0.9750647502068228, 'lambda': 2.3799985023075516, 'eta': 0.06459309846458268}. Best is trial 2 with value: 0.289645412499421.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 04:13:43,583] Trial 4 finished with value: 0.2891276865867367 and parameters: {'max_depth': 12, 'min_child_weight': 2.1985250118332513, 'subsample': 0.761706290336883, 'colsample_bytree': 0.8752049295510174, 'lambda': 6.723231084750746, 'eta': 0.04908261480571623}. Best is trial 4 with value: 0.2891276865867367.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 04:37:58,203] Trial 5 pruned. Trial was pruned at iteration 146.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 04:38:19,658] Trial 6 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 04:59:46,238] Trial 7 finished with value: 0.2934248396373904 and parameters: {'max_depth': 9, 'min_child_weight': 4.333159746892317, 'subsample': 0.7295464889457157, 'colsample_bytree': 0.8596620612545207, 'lambda': 4.188619108226963, 'eta': 0.21822126884966023}. Best is trial 4 with value: 0.2891276865867367.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 05:00:06,038] Trial 8 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 05:50:11,116] Trial 9 finished with value: 0.2919650588929062 and parameters: {'max_depth': 7, 'min_child_weight': 1.0128419250648237, 'subsample': 0.546131172923376, 'colsample_bytree': 0.8546971968626064, 'lambda': 5.291021407975452, 'eta': 0.10673661296072598}. Best is trial 4 with value: 0.2891276865867367.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 05:50:33,086] Trial 10 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 05:50:53,145] Trial 11 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 05:51:14,021] Trial 12 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 05:51:33,814] Trial 13 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 06:48:07,069] Trial 14 finished with value: 0.2900458993273704 and parameters: {'max_depth': 7, 'min_child_weight': 5.756512909572162, 'subsample': 0.6449059270855146, 'colsample_bytree': 0.9198297640193214, 'lambda': 2.115630095260182, 'eta': 0.09763705328094417}. Best is trial 4 with value: 0.2891276865867367.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 06:48:28,115] Trial 15 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 06:48:48,199] Trial 16 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 07:40:38,196] Trial 17 finished with value: 0.28867654652693947 and parameters: {'max_depth': 8, 'min_child_weight': 5.361891734274888, 'subsample': 0.9618841777880232, 'colsample_bytree': 0.6582241534026132, 'lambda': 8.002051385874758, 'eta': 0.10167697633502167}. Best is trial 17 with value: 0.28867654652693947.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 07:57:18,819] Trial 18 finished with value: 0.2928298552002892 and parameters: {'max_depth': 11, 'min_child_weight': 5.940036564846178, 'subsample': 0.9447342964452043, 'colsample_bytree': 0.6285098329592018, 'lambda': 7.955084400764418, 'eta': 0.2922977813893516}. Best is trial 17 with value: 0.28867654652693947.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 07:57:39,285] Trial 19 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 07:58:00,329] Trial 20 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 07:58:20,236] Trial 21 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 07:58:39,030] Trial 22 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 07:58:58,595] Trial 23 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 08:26:41,674] Trial 24 finished with value: 0.29003299323215104 and parameters: {'max_depth': 11, 'min_child_weight': 1.8674076626915284, 'subsample': 0.8350222840273821, 'colsample_bytree': 0.6930094877928307, 'lambda': 8.61748217546385, 'eta': 0.12501447588573117}. Best is trial 17 with value: 0.28867654652693947.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 08:27:02,067] Trial 25 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 08:27:22,627] Trial 26 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 08:27:45,242] Trial 27 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 09:02:00,579] Trial 28 pruned. Trial was pruned at iteration 174.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 09:02:21,160] Trial 29 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 09:02:40,252] Trial 30 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 09:29:34,171] Trial 31 finished with value: 0.290577535929854 and parameters: {'max_depth': 11, 'min_child_weight': 1.6910040560603639, 'subsample': 0.8197142286177913, 'colsample_bytree': 0.6967999586470214, 'lambda': 8.282960862310418, 'eta': 0.12828231309773894}. Best is trial 17 with value: 0.28867654652693947.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 09:49:26,992] Trial 32 finished with value: 0.29168081752985525 and parameters: {'max_depth': 12, 'min_child_weight': 1.9269070749473243, 'subsample': 0.8418719663027149, 'colsample_bytree': 0.6838498412182695, 'lambda': 9.849185508886809, 'eta': 0.17914137983552253}. Best is trial 17 with value: 0.28867654652693947.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 10:14:07,174] Trial 33 finished with value: 0.29188110993423405 and parameters: {'max_depth': 11, 'min_child_weight': 1.431095948196229, 'subsample': 0.7125343952920604, 'colsample_bytree': 0.7566911929332866, 'lambda': 7.0811863782447295, 'eta': 0.14295291954657957}. Best is trial 17 with value: 0.28867654652693947.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 10:14:28,995] Trial 34 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 10:33:01,111] Trial 35 finished with value: 0.2927635385193692 and parameters: {'max_depth': 10, 'min_child_weight': 3.6406892272699247, 'subsample': 0.8220973961799578, 'colsample_bytree': 0.7587948003637034, 'lambda': 7.5732871750599315, 'eta': 0.23054887870055552}. Best is trial 17 with value: 0.28867654652693947.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 10:33:23,116] Trial 36 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 10:33:43,656] Trial 37 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 10:34:04,174] Trial 38 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 10:54:05,261] Trial 39 finished with value: 0.2918177976161026 and parameters: {'max_depth': 11, 'min_child_weight': 1.4396064088715315, 'subsample': 0.7344107974844878, 'colsample_bytree': 0.7261820491584801, 'lambda': 7.897380874805487, 'eta': 0.17224656478912012}. Best is trial 17 with value: 0.28867654652693947.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 10:54:25,529] Trial 40 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 10:54:45,739] Trial 41 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 10:55:05,706] Trial 42 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 10:55:26,175] Trial 43 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 10:55:46,531] Trial 44 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 10:56:06,222] Trial 45 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 10:56:27,298] Trial 46 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 10:56:48,221] Trial 47 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 11:02:49,170] Trial 48 pruned. Trial was pruned at iteration 36.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 11:23:37,507] Trial 49 finished with value: 0.2923785825541405 and parameters: {'max_depth': 12, 'min_child_weight': 5.569308315086402, 'subsample': 0.7216649831330747, 'colsample_bytree': 0.9242985489114115, 'lambda': 1.7328605557591312, 'eta': 0.14878599580636395}. Best is trial 17 with value: 0.28867654652693947.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 11:23:57,622] Trial 50 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 11:50:47,463] Trial 51 finished with value: 0.2904439994982651 and parameters: {'max_depth': 11, 'min_child_weight': 1.7067186991626209, 'subsample': 0.8276888421575018, 'colsample_bytree': 0.6965845825650367, 'lambda': 8.327507369703344, 'eta': 0.12961030032731954}. Best is trial 17 with value: 0.28867654652693947.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 11:51:09,284] Trial 52 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 12:10:21,142] Trial 53 finished with value: 0.2912669564988149 and parameters: {'max_depth': 10, 'min_child_weight': 1.9260657217057209, 'subsample': 0.8460890711545402, 'colsample_bytree': 0.7815475342859417, 'lambda': 7.873726145476933, 'eta': 0.18509420179264915}. Best is trial 17 with value: 0.28867654652693947.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 12:10:47,768] Trial 54 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 12:17:07,138] Trial 55 pruned. Trial was pruned at iteration 35.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 12:17:27,886] Trial 56 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 12:17:48,052] Trial 57 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 12:31:33,532] Trial 58 pruned. Trial was pruned at iteration 69.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 13:00:13,130] Trial 59 finished with value: 0.2905396686521372 and parameters: {'max_depth': 12, 'min_child_weight': 5.460701371957095, 'subsample': 0.7393532109923847, 'colsample_bytree': 0.6186698349434505, 'lambda': 8.953388245403577, 'eta': 0.1337605283619569}. Best is trial 17 with value: 0.28867654652693947.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 13:00:34,042] Trial 60 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 13:00:55,325] Trial 61 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 13:01:17,358] Trial 62 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 13:25:55,610] Trial 63 finished with value: 0.29055902263424527 and parameters: {'max_depth': 12, 'min_child_weight': 5.008555570669058, 'subsample': 0.7925256329691098, 'colsample_bytree': 0.9740117198307867, 'lambda': 9.02569758469706, 'eta': 0.14206727256965}. Best is trial 17 with value: 0.28867654652693947.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 13:26:16,512] Trial 64 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 13:37:05,560] Trial 65 pruned. Trial was pruned at iteration 55.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 14:01:02,268] Trial 66 finished with value: 0.29159888325610417 and parameters: {'max_depth': 11, 'min_child_weight': 5.579655475584983, 'subsample': 0.73887736039029, 'colsample_bytree': 0.7133048678321241, 'lambda': 6.649521433911328, 'eta': 0.1619195718111225}. Best is trial 17 with value: 0.28867654652693947.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 14:01:23,564] Trial 67 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 14:01:44,555] Trial 68 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 14:16:18,819] Trial 69 pruned. Trial was pruned at iteration 71.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 14:16:39,534] Trial 70 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 14:41:38,260] Trial 71 finished with value: 0.2900325480060671 and parameters: {'max_depth': 12, 'min_child_weight': 4.747134572444972, 'subsample': 0.7945627235224213, 'colsample_bytree': 0.9862586954777832, 'lambda': 9.204648739347649, 'eta': 0.13760189033907874}. Best is trial 17 with value: 0.28867654652693947.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 15:03:47,476] Trial 72 finished with value: 0.29047762515827125 and parameters: {'max_depth': 12, 'min_child_weight': 4.1069492899879725, 'subsample': 0.796119637708633, 'colsample_bytree': 0.9403751265411532, 'lambda': 9.861264502454208, 'eta': 0.14156930286878613}. Best is trial 17 with value: 0.28867654652693947.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 15:04:10,988] Trial 73 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 15:21:46,318] Trial 74 finished with value: 0.29161408754385326 and parameters: {'max_depth': 12, 'min_child_weight': 3.869155950851884, 'subsample': 0.7972166802205117, 'colsample_bytree': 0.9535259226300793, 'lambda': 9.97624934563475, 'eta': 0.190804486213419}. Best is trial 17 with value: 0.28867654652693947.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 15:22:07,131] Trial 75 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 15:22:28,021] Trial 76 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 15:22:49,209] Trial 77 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 15:47:08,829] Trial 78 finished with value: 0.2904243638654457 and parameters: {'max_depth': 10, 'min_child_weight': 4.132390094103499, 'subsample': 0.8993273122996658, 'colsample_bytree': 0.9087939041310749, 'lambda': 2.9854643354936115, 'eta': 0.16735612676114167}. Best is trial 17 with value: 0.28867654652693947.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 16:10:08,653] Trial 79 finished with value: 0.29034723898722226 and parameters: {'max_depth': 10, 'min_child_weight': 3.263536891778843, 'subsample': 0.999929881550403, 'colsample_bytree': 0.9639870735699917, 'lambda': 2.865840745108778, 'eta': 0.16428337254979788}. Best is trial 17 with value: 0.28867654652693947.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 16:31:00,661] Trial 80 finished with value: 0.290483821734899 and parameters: {'max_depth': 10, 'min_child_weight': 3.5482479307679955, 'subsample': 0.9426412746148711, 'colsample_bytree': 0.8884356663366519, 'lambda': 3.066846008880979, 'eta': 0.16428091126703193}. Best is trial 17 with value: 0.28867654652693947.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 16:31:21,837] Trial 81 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 16:31:42,389] Trial 82 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 16:32:03,601] Trial 83 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 16:42:19,216] Trial 84 pruned. Trial was pruned at iteration 55.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 16:51:38,998] Trial 85 pruned. Trial was pruned at iteration 51.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 16:51:59,142] Trial 86 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 17:06:44,177] Trial 87 pruned. Trial was pruned at iteration 74.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 17:07:04,167] Trial 88 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 17:07:24,158] Trial 89 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 17:21:35,331] Trial 90 pruned. Trial was pruned at iteration 76.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 17:42:14,721] Trial 91 finished with value: 0.2911398729245011 and parameters: {'max_depth': 12, 'min_child_weight': 3.9844829322246014, 'subsample': 0.7702449474336215, 'colsample_bytree': 0.9406176058757088, 'lambda': 3.989698131647266, 'eta': 0.14963448790949133}. Best is trial 17 with value: 0.28867654652693947.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 17:42:35,260] Trial 92 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 17:42:57,407] Trial 93 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 17:43:17,856] Trial 94 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 17:43:39,237] Trial 95 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 18:01:51,195] Trial 96 finished with value: 0.2916859928447727 and parameters: {'max_depth': 12, 'min_child_weight': 2.869411932057625, 'subsample': 0.970654747865119, 'colsample_bytree': 0.9277464369828698, 'lambda': 2.1145159415607253, 'eta': 0.1708337060130787}. Best is trial 17 with value: 0.28867654652693947.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 18:02:12,579] Trial 97 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 18:02:32,783] Trial 98 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 18:02:54,149] Trial 99 pruned. Trial was pruned at iteration 0.\n"
     ]
    }
   ],
   "source": [
    "# Create an Optuna study and optimize the objective function\n",
    "study = optuna.create_study(direction='minimize', sampler=optuna.samplers.TPESampler(seed=7))\n",
    "study.optimize(objective, n_trials=100, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-22T16:02:54.161400Z",
     "iopub.status.busy": "2025-06-22T16:02:54.160094Z",
     "iopub.status.idle": "2025-06-22T16:02:54.167908Z",
     "shell.execute_reply": "2025-06-22T16:02:54.167536Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters:  {'max_depth': 8, 'min_child_weight': 5.361891734274888, 'subsample': 0.9618841777880232, 'colsample_bytree': 0.6582241534026132, 'lambda': 8.002051385874758, 'eta': 0.10167697633502167}\n",
      "Best loss:  0.28867654652693947\n"
     ]
    }
   ],
   "source": [
    "# Print the best hyperparameters and the best RMSE\n",
    "best_params = study.best_params\n",
    "best_loss = study.best_value\n",
    "print(\"Best Hyperparameters: \", best_params)\n",
    "print(\"Best loss: \", best_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrain the model with best hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best Hyperparameters:    \n",
    "{'max_depth': 8,   \n",
    "'min_child_weight': 5.361891734274888,   \n",
    "'subsample': 0.9618841777880232,   \n",
    "'colsample_bytree': 0.6582241534026132,   \n",
    "'lambda': 8.002051385874758,   \n",
    "'eta': 0.10167697633502167}   \n",
    "Best loss:  0.28867654652693947"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-mlogloss:2.27924\tvalidation-mlogloss:2.27826\n",
      "[10]\ttrain-mlogloss:0.86822\tvalidation-mlogloss:0.87787\n",
      "[20]\ttrain-mlogloss:0.52777\tvalidation-mlogloss:0.54007\n",
      "[30]\ttrain-mlogloss:0.39563\tvalidation-mlogloss:0.41083\n",
      "[40]\ttrain-mlogloss:0.33701\tvalidation-mlogloss:0.35479\n",
      "[50]\ttrain-mlogloss:0.30929\tvalidation-mlogloss:0.32869\n",
      "[60]\ttrain-mlogloss:0.29446\tvalidation-mlogloss:0.31527\n",
      "[70]\ttrain-mlogloss:0.28559\tvalidation-mlogloss:0.30757\n",
      "[80]\ttrain-mlogloss:0.27969\tvalidation-mlogloss:0.30293\n",
      "[90]\ttrain-mlogloss:0.27527\tvalidation-mlogloss:0.29973\n",
      "[100]\ttrain-mlogloss:0.27176\tvalidation-mlogloss:0.29753\n",
      "[110]\ttrain-mlogloss:0.26821\tvalidation-mlogloss:0.29562\n",
      "[120]\ttrain-mlogloss:0.26534\tvalidation-mlogloss:0.29443\n",
      "[130]\ttrain-mlogloss:0.26253\tvalidation-mlogloss:0.29344\n",
      "[140]\ttrain-mlogloss:0.25977\tvalidation-mlogloss:0.29254\n",
      "[150]\ttrain-mlogloss:0.25704\tvalidation-mlogloss:0.29177\n",
      "[160]\ttrain-mlogloss:0.25449\tvalidation-mlogloss:0.29134\n",
      "[170]\ttrain-mlogloss:0.25191\tvalidation-mlogloss:0.29088\n",
      "[180]\ttrain-mlogloss:0.24959\tvalidation-mlogloss:0.29051\n",
      "[190]\ttrain-mlogloss:0.24703\tvalidation-mlogloss:0.29007\n",
      "[200]\ttrain-mlogloss:0.24482\tvalidation-mlogloss:0.28982\n",
      "[210]\ttrain-mlogloss:0.24250\tvalidation-mlogloss:0.28961\n",
      "[220]\ttrain-mlogloss:0.24040\tvalidation-mlogloss:0.28942\n",
      "[230]\ttrain-mlogloss:0.23825\tvalidation-mlogloss:0.28923\n",
      "[240]\ttrain-mlogloss:0.23606\tvalidation-mlogloss:0.28901\n",
      "[250]\ttrain-mlogloss:0.23414\tvalidation-mlogloss:0.28884\n",
      "[260]\ttrain-mlogloss:0.23237\tvalidation-mlogloss:0.28883\n",
      "[270]\ttrain-mlogloss:0.23036\tvalidation-mlogloss:0.28868\n",
      "[280]\ttrain-mlogloss:0.22841\tvalidation-mlogloss:0.28870\n",
      "[289]\ttrain-mlogloss:0.22652\tvalidation-mlogloss:0.28868\n"
     ]
    }
   ],
   "source": [
    "param = {\n",
    "        'objective': 'multi:softprob',\n",
    "        'eval_metric': 'mlogloss',\n",
    "        'num_class': num_act,\n",
    "        'max_depth': 8,\n",
    "        'min_child_weight': 5.361891734274888,\n",
    "        'subsample': 0.9618841777880232,\n",
    "        'colsample_bytree': 0.6582241534026132,\n",
    "        'lambda': 8.002051385874758,\n",
    "        'eta': 0.10167697633502167\n",
    "    }\n",
    "\n",
    "dtrain = xgb.DMatrix(data=X_train, label=y_train)\n",
    "dvalid = xgb.DMatrix(data=X_val, label=y_val)\n",
    "\n",
    "model = xgb.train(param, \n",
    "                   dtrain, \n",
    "                   evals=[(dtrain, 'train'), (dvalid, 'validation')], \n",
    "                   num_boost_round = 100000,\n",
    "                   early_stopping_rounds=20,\n",
    "                   verbose_eval=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_model(\"xgb_2017_20250621_2.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = xgb.Booster()\n",
    "model.load_model(\"xgb_2017_20250621_2.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150877, 29)\n",
      "[8.66868595e-06 8.66874325e-06 8.66873506e-06 5.62735404e-05\n",
      " 8.66880146e-06 6.42681837e-01 2.98163050e-05 2.37068117e-01\n",
      " 1.19678110e-01 1.16176365e-04 7.69391845e-05 4.12472946e-06\n",
      " 1.47358805e-05 2.47646894e-05 6.11837231e-06 4.30179389e-05\n",
      " 1.92481366e-05 6.19082402e-06 1.21121366e-05 8.09033554e-06\n",
      " 1.75395053e-05 6.59329180e-06 2.70536166e-05 1.36669469e-05\n",
      " 3.87922091e-06 1.63274581e-05 4.30776117e-06 2.12152354e-05\n",
      " 9.03822092e-06]\n",
      "(150877,)\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "dvalid = xgb.DMatrix(X_val)\n",
    "\n",
    "preds = model.predict(dvalid)  # shape: (num_samples, num_class)\n",
    "print(preds.shape)\n",
    "print(preds[0])\n",
    "pred_labels = preds.argmax(axis=1)  # shape: (num_samples,)\n",
    "print(pred_labels.shape)\n",
    "print(pred_labels[0])\n",
    "pred_labels_tensor = torch.from_numpy(pred_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: tensor(0.892)\n",
      "Validation Macro Precision: tensor(0.818)\n",
      "Validation Macro Recall: tensor(0.751)\n",
      "Validation Macro F1 score: tensor(0.762)\n"
     ]
    }
   ],
   "source": [
    "accuracy, precision_macro, recall_macro, f1_macro = calculate_metrics(pred_labels_tensor, y_val_tensor, device, num_act)\n",
    "print('Validation Accuracy:', accuracy)\n",
    "print('Validation Macro Precision:', precision_macro)\n",
    "print('Validation Macro Recall:', recall_macro)\n",
    "print('Validation Macro F1 score:', f1_macro)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(241181, 29)\n",
      "[8.66868595e-06 8.66874325e-06 8.66873506e-06 5.62735404e-05\n",
      " 8.66880146e-06 6.42681837e-01 2.98163050e-05 2.37068117e-01\n",
      " 1.19678110e-01 1.16176365e-04 7.69391845e-05 4.12472946e-06\n",
      " 1.47358805e-05 2.47646894e-05 6.11837231e-06 4.30179389e-05\n",
      " 1.92481366e-05 6.19082402e-06 1.21121366e-05 8.09033554e-06\n",
      " 1.75395053e-05 6.59329180e-06 2.70536166e-05 1.36669469e-05\n",
      " 3.87922091e-06 1.63274581e-05 4.30776117e-06 2.12152354e-05\n",
      " 9.03822092e-06]\n",
      "(241181,)\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "dtest = xgb.DMatrix(X_test)\n",
    "\n",
    "preds = model.predict(dtest)  # shape: (num_samples, num_class)\n",
    "print(preds.shape)\n",
    "print(preds[0])\n",
    "pred_labels = preds.argmax(axis=1)  # shape: (num_samples,)\n",
    "print(pred_labels.shape)\n",
    "print(pred_labels[0])\n",
    "pred_labels_tensor = torch.from_numpy(pred_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: tensor(0.887)\n",
      "Test Macro Precision: tensor(0.813)\n",
      "Test Macro Recall: tensor(0.756)\n",
      "Test Macro F1 score: tensor(0.765)\n"
     ]
    }
   ],
   "source": [
    "accuracy, precision_macro, recall_macro, f1_macro = calculate_metrics(pred_labels_tensor, y_test_tensor, device, num_act)\n",
    "print('Test Accuracy:', accuracy)\n",
    "print('Test Macro Precision:', precision_macro)\n",
    "print('Test Macro Recall:', recall_macro)\n",
    "print('Test Macro F1 score:', f1_macro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_np = y_test_tensor.cpu().numpy()\n",
    "y_pred_np = pred_labels_tensor.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.955735</td>\n",
       "      <td>0.986687</td>\n",
       "      <td>0.970964</td>\n",
       "      <td>7812.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.639579</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.780175</td>\n",
       "      <td>3707.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.974335</td>\n",
       "      <td>0.978366</td>\n",
       "      <td>0.976346</td>\n",
       "      <td>8459.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.851255</td>\n",
       "      <td>0.884059</td>\n",
       "      <td>0.867347</td>\n",
       "      <td>26936.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.998284</td>\n",
       "      <td>0.903398</td>\n",
       "      <td>0.948474</td>\n",
       "      <td>5797.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.727885</td>\n",
       "      <td>0.400067</td>\n",
       "      <td>0.516339</td>\n",
       "      <td>5944.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.956242</td>\n",
       "      <td>0.720722</td>\n",
       "      <td>0.821943</td>\n",
       "      <td>8035.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8073.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.833699</td>\n",
       "      <td>0.973436</td>\n",
       "      <td>0.898165</td>\n",
       "      <td>7416.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.913787</td>\n",
       "      <td>0.992104</td>\n",
       "      <td>0.951336</td>\n",
       "      <td>37232.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5948.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.967631</td>\n",
       "      <td>0.836642</td>\n",
       "      <td>0.897381</td>\n",
       "      <td>5038.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.819271</td>\n",
       "      <td>0.908009</td>\n",
       "      <td>0.861360</td>\n",
       "      <td>40004.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999883</td>\n",
       "      <td>0.999941</td>\n",
       "      <td>8547.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.878400</td>\n",
       "      <td>0.868499</td>\n",
       "      <td>0.873421</td>\n",
       "      <td>5057.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.646154</td>\n",
       "      <td>0.310345</td>\n",
       "      <td>0.419301</td>\n",
       "      <td>406.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.870101</td>\n",
       "      <td>0.878102</td>\n",
       "      <td>0.874083</td>\n",
       "      <td>38278.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999815</td>\n",
       "      <td>0.999907</td>\n",
       "      <td>5391.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.439024</td>\n",
       "      <td>0.043186</td>\n",
       "      <td>0.078637</td>\n",
       "      <td>2084.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.388087</td>\n",
       "      <td>0.054211</td>\n",
       "      <td>0.095133</td>\n",
       "      <td>3966.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4079.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>952.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.977906</td>\n",
       "      <td>0.869342</td>\n",
       "      <td>0.920434</td>\n",
       "      <td>1171.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.905728</td>\n",
       "      <td>0.904648</td>\n",
       "      <td>0.905188</td>\n",
       "      <td>839.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.886712</td>\n",
       "      <td>0.886712</td>\n",
       "      <td>0.886712</td>\n",
       "      <td>0.886712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.812581</td>\n",
       "      <td>0.756461</td>\n",
       "      <td>0.765059</td>\n",
       "      <td>241181.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.875161</td>\n",
       "      <td>0.886712</td>\n",
       "      <td>0.874016</td>\n",
       "      <td>241181.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score        support\n",
       "3              0.955735  0.986687  0.970964    7812.000000\n",
       "5              0.639579  1.000000  0.780175    3707.000000\n",
       "6              0.974335  0.978366  0.976346    8459.000000\n",
       "7              0.851255  0.884059  0.867347   26936.000000\n",
       "8              0.998284  0.903398  0.948474    5797.000000\n",
       "9              0.727885  0.400067  0.516339    5944.000000\n",
       "10             0.956242  0.720722  0.821943    8035.000000\n",
       "11             1.000000  1.000000  1.000000    8073.000000\n",
       "12             0.833699  0.973436  0.898165    7416.000000\n",
       "13             0.913787  0.992104  0.951336   37232.000000\n",
       "14             1.000000  1.000000  1.000000    5948.000000\n",
       "15             0.967631  0.836642  0.897381    5038.000000\n",
       "16             0.819271  0.908009  0.861360   40004.000000\n",
       "17             1.000000  0.999883  0.999941    8547.000000\n",
       "18             0.878400  0.868499  0.873421    5057.000000\n",
       "19             0.646154  0.310345  0.419301     406.000000\n",
       "20             0.870101  0.878102  0.874083   38278.000000\n",
       "21             1.000000  0.999815  0.999907    5391.000000\n",
       "22             0.439024  0.043186  0.078637    2084.000000\n",
       "23             0.388087  0.054211  0.095133    3966.000000\n",
       "24             1.000000  1.000000  1.000000    4079.000000\n",
       "25             0.000000  0.000000  0.000000     952.000000\n",
       "26             0.977906  0.869342  0.920434    1171.000000\n",
       "27             0.905728  0.904648  0.905188     839.000000\n",
       "28             0.571429  0.400000  0.470588      10.000000\n",
       "accuracy       0.886712  0.886712  0.886712       0.886712\n",
       "macro avg      0.812581  0.756461  0.765059  241181.000000\n",
       "weighted avg   0.875161  0.886712  0.874016  241181.000000"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "report_dict = classification_report(y_true_np, y_pred_np, output_dict=True)\n",
    "# Convert to DataFrame for tabular view\n",
    "report_df = pd.DataFrame(report_dict).transpose()\n",
    "report_df.to_csv('2017_xgb.csv')\n",
    "report_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    precision    recall  f1-score\n",
      "3    0.955735  0.986687  0.970964\n",
      "5    0.639579  1.000000  0.780175\n",
      "6    0.974335  0.978366  0.976346\n",
      "7    0.851255  0.884059  0.867347\n",
      "8    0.998284  0.903398  0.948474\n",
      "9    0.727885  0.400067  0.516339\n",
      "10   0.956242  0.720722  0.821943\n",
      "11   1.000000  1.000000  1.000000\n",
      "12   0.833699  0.973436  0.898165\n",
      "13   0.913787  0.992104  0.951336\n",
      "14   1.000000  1.000000  1.000000\n",
      "15   0.967631  0.836642  0.897381\n",
      "16   0.819271  0.908009  0.861360\n",
      "17   1.000000  0.999883  0.999941\n",
      "18   0.878400  0.868499  0.873421\n",
      "19   0.646154  0.310345  0.419301\n",
      "20   0.870101  0.878102  0.874083\n",
      "21   1.000000  0.999815  0.999907\n",
      "22   0.439024  0.043186  0.078637\n",
      "23   0.388087  0.054211  0.095133\n",
      "24   1.000000  1.000000  1.000000\n",
      "25   0.000000  0.000000  0.000000\n",
      "26   0.977906  0.869342  0.920434\n",
      "27   0.905728  0.904648  0.905188\n",
      "28   0.571429  0.400000  0.470588\n"
     ]
    }
   ],
   "source": [
    "# Only keep rows for actual class labels (exclude \"accuracy\", \"macro avg\", etc.)\n",
    "report_df = report_df[report_df.index.str.isdigit()]\n",
    "\n",
    "# Display the result\n",
    "print(report_df[['precision', 'recall', 'f1-score']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3195794/3649599814.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  report_df['support (%)'] = 100.0 * report_df['support'] / total_support\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "      <th>support (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.955735</td>\n",
       "      <td>0.986687</td>\n",
       "      <td>0.970964</td>\n",
       "      <td>7812.0</td>\n",
       "      <td>3.239061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.639579</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.780175</td>\n",
       "      <td>3707.0</td>\n",
       "      <td>1.537020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.974335</td>\n",
       "      <td>0.978366</td>\n",
       "      <td>0.976346</td>\n",
       "      <td>8459.0</td>\n",
       "      <td>3.507324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.851255</td>\n",
       "      <td>0.884059</td>\n",
       "      <td>0.867347</td>\n",
       "      <td>26936.0</td>\n",
       "      <td>11.168376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.998284</td>\n",
       "      <td>0.903398</td>\n",
       "      <td>0.948474</td>\n",
       "      <td>5797.0</td>\n",
       "      <td>2.403589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.727885</td>\n",
       "      <td>0.400067</td>\n",
       "      <td>0.516339</td>\n",
       "      <td>5944.0</td>\n",
       "      <td>2.464539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.956242</td>\n",
       "      <td>0.720722</td>\n",
       "      <td>0.821943</td>\n",
       "      <td>8035.0</td>\n",
       "      <td>3.331523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8073.0</td>\n",
       "      <td>3.347279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.833699</td>\n",
       "      <td>0.973436</td>\n",
       "      <td>0.898165</td>\n",
       "      <td>7416.0</td>\n",
       "      <td>3.074869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.913787</td>\n",
       "      <td>0.992104</td>\n",
       "      <td>0.951336</td>\n",
       "      <td>37232.0</td>\n",
       "      <td>15.437369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5948.0</td>\n",
       "      <td>2.466198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.967631</td>\n",
       "      <td>0.836642</td>\n",
       "      <td>0.897381</td>\n",
       "      <td>5038.0</td>\n",
       "      <td>2.088888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.819271</td>\n",
       "      <td>0.908009</td>\n",
       "      <td>0.861360</td>\n",
       "      <td>40004.0</td>\n",
       "      <td>16.586713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999883</td>\n",
       "      <td>0.999941</td>\n",
       "      <td>8547.0</td>\n",
       "      <td>3.543811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.878400</td>\n",
       "      <td>0.868499</td>\n",
       "      <td>0.873421</td>\n",
       "      <td>5057.0</td>\n",
       "      <td>2.096765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.646154</td>\n",
       "      <td>0.310345</td>\n",
       "      <td>0.419301</td>\n",
       "      <td>406.0</td>\n",
       "      <td>0.168338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.870101</td>\n",
       "      <td>0.878102</td>\n",
       "      <td>0.874083</td>\n",
       "      <td>38278.0</td>\n",
       "      <td>15.871068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999815</td>\n",
       "      <td>0.999907</td>\n",
       "      <td>5391.0</td>\n",
       "      <td>2.235251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.439024</td>\n",
       "      <td>0.043186</td>\n",
       "      <td>0.078637</td>\n",
       "      <td>2084.0</td>\n",
       "      <td>0.864081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.388087</td>\n",
       "      <td>0.054211</td>\n",
       "      <td>0.095133</td>\n",
       "      <td>3966.0</td>\n",
       "      <td>1.644408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4079.0</td>\n",
       "      <td>1.691261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>952.0</td>\n",
       "      <td>0.394724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.977906</td>\n",
       "      <td>0.869342</td>\n",
       "      <td>0.920434</td>\n",
       "      <td>1171.0</td>\n",
       "      <td>0.485527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.905728</td>\n",
       "      <td>0.904648</td>\n",
       "      <td>0.905188</td>\n",
       "      <td>839.0</td>\n",
       "      <td>0.347872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.004146</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    precision    recall  f1-score  support  support (%)\n",
       "3    0.955735  0.986687  0.970964   7812.0     3.239061\n",
       "5    0.639579  1.000000  0.780175   3707.0     1.537020\n",
       "6    0.974335  0.978366  0.976346   8459.0     3.507324\n",
       "7    0.851255  0.884059  0.867347  26936.0    11.168376\n",
       "8    0.998284  0.903398  0.948474   5797.0     2.403589\n",
       "9    0.727885  0.400067  0.516339   5944.0     2.464539\n",
       "10   0.956242  0.720722  0.821943   8035.0     3.331523\n",
       "11   1.000000  1.000000  1.000000   8073.0     3.347279\n",
       "12   0.833699  0.973436  0.898165   7416.0     3.074869\n",
       "13   0.913787  0.992104  0.951336  37232.0    15.437369\n",
       "14   1.000000  1.000000  1.000000   5948.0     2.466198\n",
       "15   0.967631  0.836642  0.897381   5038.0     2.088888\n",
       "16   0.819271  0.908009  0.861360  40004.0    16.586713\n",
       "17   1.000000  0.999883  0.999941   8547.0     3.543811\n",
       "18   0.878400  0.868499  0.873421   5057.0     2.096765\n",
       "19   0.646154  0.310345  0.419301    406.0     0.168338\n",
       "20   0.870101  0.878102  0.874083  38278.0    15.871068\n",
       "21   1.000000  0.999815  0.999907   5391.0     2.235251\n",
       "22   0.439024  0.043186  0.078637   2084.0     0.864081\n",
       "23   0.388087  0.054211  0.095133   3966.0     1.644408\n",
       "24   1.000000  1.000000  1.000000   4079.0     1.691261\n",
       "25   0.000000  0.000000  0.000000    952.0     0.394724\n",
       "26   0.977906  0.869342  0.920434   1171.0     0.485527\n",
       "27   0.905728  0.904648  0.905188    839.0     0.347872\n",
       "28   0.571429  0.400000  0.470588     10.0     0.004146"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_support = report_df['support'].sum()\n",
    "report_df['support (%)'] = 100.0 * report_df['support'] / total_support\n",
    "report_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_freq(y):\n",
    "    unique, counts = np.unique(y, return_counts=True)\n",
    "    percentages = counts / counts.sum() * 100\n",
    "    distribution = dict(zip(unique, percentages))\n",
    "    return distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{3: 2.683543742095804,\n",
       " 5: 1.7253729829443705,\n",
       " 6: 4.013033404438078,\n",
       " 7: 12.784907621942523,\n",
       " 8: 2.683543742095804,\n",
       " 9: 2.683543742095804,\n",
       " 10: 3.5952798283343426,\n",
       " 11: 3.5952798283343426,\n",
       " 12: 3.3475754127614525,\n",
       " 13: 16.33628845916126,\n",
       " 14: 2.6719746938956632,\n",
       " 15: 1.7092080114866386,\n",
       " 16: 18.628227843687895,\n",
       " 17: 3.1218997328025306,\n",
       " 18: 1.9692738758213233,\n",
       " 19: 0.14374146188394818,\n",
       " 20: 11.82055613841019,\n",
       " 21: 1.6706973441902775,\n",
       " 22: 0.8805155041093893,\n",
       " 23: 1.4809966497304254,\n",
       " 24: 1.4809966497304254,\n",
       " 25: 0.32203158825598976,\n",
       " 26: 0.4050751671172785,\n",
       " 27: 0.21901951524103241,\n",
       " 28: 0.027417059433211727}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist_train = get_freq(y_train)\n",
    "dist_train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{3: 3.2390611200716473,\n",
       " 5: 1.5370199145040446,\n",
       " 6: 3.5073243746397935,\n",
       " 7: 11.16837561831156,\n",
       " 8: 2.4035890057674525,\n",
       " 9: 2.4645390806075107,\n",
       " 10: 3.331522798230375,\n",
       " 11: 3.3472785998897097,\n",
       " 12: 3.0748690817270017,\n",
       " 13: 15.437368615272348,\n",
       " 14: 2.4661975860453356,\n",
       " 15: 2.0888875989402154,\n",
       " 16: 16.586712883684868,\n",
       " 17: 3.543811494271937,\n",
       " 18: 2.0967654997698824,\n",
       " 19: 0.16833830193920749,\n",
       " 20: 15.871067787263508,\n",
       " 21: 2.235250703828245,\n",
       " 22: 0.8640813331066709,\n",
       " 23: 1.6444081416031944,\n",
       " 24: 1.6912609202217421,\n",
       " 25: 0.39472429420227956,\n",
       " 26: 0.48552746692318216,\n",
       " 27: 0.34787151558373175,\n",
       " 28: 0.004146263594561761}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist_train = get_freq(y_test)\n",
    "dist_train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "047f35f2391b4e7f81bcad32c665a29e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1f78ef8c30e8468fb6905568e4d43e5f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3ce83370a1294f9ea0e1ac9ab27a34b3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "3d9e15c7090c494e83f8afcaaa7cbe51": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "426fe71cbe3045f7937e67474cf1c4f0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_3d9e15c7090c494e83f8afcaaa7cbe51",
       "placeholder": "",
       "style": "IPY_MODEL_3ce83370a1294f9ea0e1ac9ab27a34b3",
       "tabbable": null,
       "tooltip": null,
       "value": "Besttrial:17.Bestvalue:0.288677:100%"
      }
     },
     "45f6893f856f4b30b2bc886fc8cfb312": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "526bb6688b514b449383f7926be97957": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "62d235b1e5a64f418e4f510e85e908a4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "abea5e72b1d04f36bc571ceac1de351a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_426fe71cbe3045f7937e67474cf1c4f0",
        "IPY_MODEL_fda57f9eb8a6409fb7aa7662052fe937",
        "IPY_MODEL_cafd54b4058f4312ab1b51a39e7f9dad"
       ],
       "layout": "IPY_MODEL_526bb6688b514b449383f7926be97957",
       "tabbable": null,
       "tooltip": null
      }
     },
     "cafd54b4058f4312ab1b51a39e7f9dad": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_1f78ef8c30e8468fb6905568e4d43e5f",
       "placeholder": "",
       "style": "IPY_MODEL_45f6893f856f4b30b2bc886fc8cfb312",
       "tabbable": null,
       "tooltip": null,
       "value": "100/100[22:38:20&lt;00:00,168.95s/it]"
      }
     },
     "fda57f9eb8a6409fb7aa7662052fe937": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_047f35f2391b4e7f81bcad32c665a29e",
       "max": 100,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_62d235b1e5a64f418e4f510e85e908a4",
       "tabbable": null,
       "tooltip": null,
       "value": 100
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
