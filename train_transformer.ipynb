{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Documentation\n",
    "Example code for training transformer on Road Traffic Fine Management dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install and import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-15T22:26:20.303896Z",
     "iopub.status.busy": "2025-02-15T22:26:20.303750Z",
     "iopub.status.idle": "2025-02-15T22:26:22.616103Z",
     "shell.execute_reply": "2025-02-15T22:26:22.615798Z"
    }
   },
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import csv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-15T22:26:22.618100Z",
     "iopub.status.busy": "2025-02-15T22:26:22.617938Z",
     "iopub.status.idle": "2025-02-15T22:26:22.621299Z",
     "shell.execute_reply": "2025-02-15T22:26:22.621104Z"
    }
   },
   "outputs": [],
   "source": [
    "from create_model import Transformer\n",
    "from train_evaluate import train, validate, EarlyStopper, init_weights_kaiming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"GPU available:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU name:\", torch.cuda.get_device_name(0))\n",
    "    print(\"Number of GPUs:\", torch.cuda.device_count())\n",
    "print(\"Number of CPUs\", os.cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-15T22:26:22.648178Z",
     "iopub.status.busy": "2025-02-15T22:26:22.648089Z",
     "iopub.status.idle": "2025-02-15T22:26:22.653657Z",
     "shell.execute_reply": "2025-02-15T22:26:22.653461Z"
    }
   },
   "outputs": [],
   "source": [
    "# set random seed\n",
    "seed = 7\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)           # Ensures reproducibility on the CPU\n",
    "torch.cuda.manual_seed_all(seed)  # Ensures reproducibility on all GPUs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-15T22:26:22.654857Z",
     "iopub.status.busy": "2025-02-15T22:26:22.654649Z",
     "iopub.status.idle": "2025-02-15T22:26:22.656422Z",
     "shell.execute_reply": "2025-02-15T22:26:22.656242Z"
    }
   },
   "outputs": [],
   "source": [
    "# define file path\n",
    "train_trace_act_tensor_path = '.../train_trace_act.pt'\n",
    "train_trace_time_tensor_path = '.../train_trace_time.pt'\n",
    "\n",
    "val_trace_act_tensor_path = '.../val_trace_act.pt'\n",
    "val_trace_time_tensor_path = '...val_trace_time.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-15T22:26:22.657317Z",
     "iopub.status.busy": "2025-02-15T22:26:22.657228Z",
     "iopub.status.idle": "2025-02-15T22:26:22.658666Z",
     "shell.execute_reply": "2025-02-15T22:26:22.658491Z"
    }
   },
   "outputs": [],
   "source": [
    "# define prefix length\n",
    "prefix_len = 6\n",
    "num_act = 13\n",
    "num_time_features = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model design hyperparameters\n",
    "d_embed = 4\n",
    "d_model = 16\n",
    "num_heads = 4\n",
    "d_ff = d_model * 2\n",
    "num_layers = 2\n",
    "dropout = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-15T22:26:22.661750Z",
     "iopub.status.busy": "2025-02-15T22:26:22.661555Z",
     "iopub.status.idle": "2025-02-15T22:26:22.663088Z",
     "shell.execute_reply": "2025-02-15T22:26:22.662918Z"
    }
   },
   "outputs": [],
   "source": [
    "# define model training hyperparameters\n",
    "batch_size = 64\n",
    "\n",
    "lr = 0.0003\n",
    "\n",
    "num_epochs = 200\n",
    "\n",
    "loss_mode = 'base'\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `train_trace_act_tensor` has the shape `(num_samples, prefix_len + 1)`.  \n",
    "- It contains the full activity label trace (from the first event to the EOC token), represented by indices and right-padded with zeros.\n",
    "- Input and target sequences are derived from this tensor as follows:\n",
    "    - Input sequence: obtained by removing the last element of the trace and replacing any EOC token (index 3) with 0 (padding).\n",
    "    - Target sequence: obtained by removing the first element of the trace.\n",
    "    - For example, given a trace [4, 5, 7, 8, 3, 0, 0, 0], the input sequence becomes [4, 5, 7, 8, 0, 0, 0], and the target sequence becomes [5, 7, 8, 3, 0, 0, 0]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-15T22:26:23.620201Z",
     "iopub.status.busy": "2025-02-15T22:26:23.620111Z",
     "iopub.status.idle": "2025-02-15T22:26:26.825265Z",
     "shell.execute_reply": "2025-02-15T22:26:26.824946Z"
    }
   },
   "outputs": [],
   "source": [
    "train_trace_act_tensor = torch.load(train_trace_act_tensor_path)\n",
    "\n",
    "# prepare input sequence\n",
    "train_prefix_act = train_trace_act_tensor[:, :-1].clone()\n",
    "train_prefix_act[train_prefix_act == 3] = 0\n",
    "\n",
    "# prepare target sequence\n",
    "train_tgt = train_trace_act_tensor[:, 1:].clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_trace_time_tensor = torch.load(train_trace_time_tensor_path)\n",
    "\n",
    "# prepare input sequence\n",
    "train_prefix_time = train_trace_time_tensor[:, :-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(train_prefix_act, \n",
    "                              train_prefix_time, \n",
    "                              train_tgt)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-15T22:26:28.207042Z",
     "iopub.status.busy": "2025-02-15T22:26:28.206941Z",
     "iopub.status.idle": "2025-02-15T22:26:28.852168Z",
     "shell.execute_reply": "2025-02-15T22:26:28.851862Z"
    }
   },
   "outputs": [],
   "source": [
    "val_trace_act_tensor = torch.load(val_trace_act_tensor_path)\n",
    "\n",
    "# prepare input sequence\n",
    "val_prefix_act = val_trace_act_tensor[:, :-1].clone()\n",
    "val_prefix_act[val_prefix_act == 3] = 0\n",
    "\n",
    "# prepare target sequence\n",
    "val_tgt = val_trace_act_tensor[:, 1:].clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_trace_time_tensor = torch.load(val_trace_time_tensor_path)\n",
    "\n",
    "# prepare input sequence\n",
    "val_prefix_time = val_trace_time_tensor[:, :-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = TensorDataset(val_prefix_act, \n",
    "                            val_prefix_time, \n",
    "                            val_tgt)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define trial function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trial(model,\n",
    "          lr,\n",
    "          model_state_path,\n",
    "          best_val_loss=float(\"inf\"),\n",
    "          early_stopper=None):\n",
    "\n",
    "    results = []\n",
    "\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=lr)\n",
    "\n",
    "    if early_stopper is None:\n",
    "        early_stopper = EarlyStopper(patience=10, delta=0.001)\n",
    "\n",
    "    for epoch in tqdm.tqdm(range(num_epochs)):\n",
    "\n",
    "        train_loss = train(model,\n",
    "                            train_dataloader,\n",
    "                            optimizer,\n",
    "                            device,\n",
    "                            loss_mode)\n",
    "        \n",
    "        val_loss, accuracy, precision_macro, recall_macro, f1_macro = validate(model,\n",
    "                                        val_dataloader,\n",
    "                                        device,\n",
    "                                        num_act,\n",
    "                                        loss_mode)\n",
    "        \n",
    "        print(f\"\\tTrain Loss: {train_loss:7.3f} | Val Loss: {val_loss:7.3f} | Val Accuracy: {accuracy:7.3f}\")\n",
    "        print(f\"\\tVal Precision: {precision_macro:7.3f}| Val Recall: {recall_macro:7.3f}| Val macro F1: {f1_macro:7.3f}\")\n",
    "\n",
    "        if val_loss < (best_val_loss - 0.001):\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), model_state_path)\n",
    "\n",
    "        # Store metrics in the results list as a dictionary\n",
    "        results.append({\n",
    "            'epoch': epoch + 1,\n",
    "            'train_loss': train_loss,\n",
    "            'val_loss': val_loss,\n",
    "            'val_accuracy': accuracy,\n",
    "            'val_precision': precision_macro,\n",
    "            'val_recall': recall_macro,\n",
    "            'val_f1_score': f1_macro\n",
    "            })\n",
    "        \n",
    "        # early stopping\n",
    "        if early_stopper.early_stop(val_loss):     \n",
    "            print(f\"Early stopping triggered at epoch {epoch + 1}\")        \n",
    "            break\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate transformer\n",
    "model = Transformer(prefix_len, \n",
    "                 num_act, num_time_features, d_embed, \n",
    "                 d_model, num_heads, d_ff, dropout,\n",
    "                 num_layers).to(device)\n",
    "\n",
    "# apply weight initialization\n",
    "model.apply(init_weights_kaiming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = trial(model, lr,\n",
    "            \".../experiment1_1_parameters.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-16T09:06:01.185485Z",
     "iopub.status.busy": "2025-02-16T09:06:01.185170Z",
     "iopub.status.idle": "2025-02-16T09:06:01.187198Z",
     "shell.execute_reply": "2025-02-16T09:06:01.187007Z"
    }
   },
   "outputs": [],
   "source": [
    "# After the loop, save the results to a CSV file\n",
    "csv_file = '.../experiment1_1_loss.csv'\n",
    "csv_columns = ['epoch', 'train_loss', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_f1_score']\n",
    "\n",
    "try:\n",
    "    with open(csv_file, mode='w', newline='') as file:\n",
    "        writer = csv.DictWriter(file, fieldnames=csv_columns)\n",
    "        writer.writeheader()\n",
    "        writer.writerows(results)\n",
    "    print(f\"Metrics saved to {csv_file}\")\n",
    "except IOError as e:\n",
    "    print(\"I/O error\", e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
